# 2.3.4. 실습: 실시간 ETL 파이프라인 구현

## 실습 목표
* Kinesis Data Firehose + Lambda를 활용한 실시간 ETL 구현
* 데이터 변환 및 품질 검증 적용
* S3에 파티션된 형태로 저장

## Step 1: Lambda 변환 함수 생성

### Lambda 함수 소스 코드
* 파일: `2.3.4.src/etl_transform.py`
* 주요 기능:
    - 실시간 데이터 변환 처리
    - IP 주소 익명화
    - HTTP 상태 코드 분류
    - 오류 처리 및 로깅

### Lambda 함수 배포
실행: `bash 2.3.4.src/deploy_lambda.sh`

주요 작업:
* Lambda 함수 패키징 및 업로드
* IAM 역할 생성 및 권한 설정
* 함수 생성 및 구성

## Step 2: S3 버킷 및 Firehose 설정

### 인프라 설정 자동화
실행: `bash 2.3.4.src/setup_firehose.sh`

주요 작업:
* S3 버킷 생성 (타임스탬프 기반 유니크 이름)
* Firehose IAM 역할 및 정책 생성
* Kinesis Data Firehose 스트림 생성
    - Lambda 변환 프로세서 연결
    - S3 파티션 구조 설정 (year/month/day/hour)
    - GZIP 압축 활성화
    - 오류 데이터 별도 경로 저장

## Step 3: 테스트 데이터 전송

### 테스트 스크립트 실행
파일: `2.3.4.src/test_etl.py`

실행:
```bash
python 2.3.4.src/test_etl.py
```

테스트 데이터 특징:
* 사용자 로그 이벤트 시뮬레이션
* 다양한 HTTP 상태 코드 포함
* 25개 배치 단위로 전송
* 총 200개 레코드 생성

## Step 4: 결과 확인

### 자동 결과 확인
실행: `bash 2.3.4.src/check_results.sh <bucket-name>`

확인 항목:
* S3 변환된 데이터 목록
* 오류 데이터 확인
* CloudWatch Lambda 메트릭
* CloudWatch Firehose 메트릭

### 수동 데이터 샘플 확인
```bash
# 변환된 데이터 다운로드
aws s3 cp s3://<bucket-name>/transformed/ ./results/ --recursive

# 압축 해제 후 내용 확인
find ./results -name "*.gz" -exec gunzip {} \;
find ./results -name "*.json" -head -10
```

## Step 5: 정리

### 리소스 정리
실행: `bash 2.3.4.src/cleanup.sh <bucket-name>`

정리 대상:
* Firehose 스트림 삭제
* Lambda 함수 삭제
* S3 버킷 및 데이터 삭제
* IAM 역할 및 정책 삭제

## 소스 파일 구조

### 2.3.4.src/ 디렉토리
| 파일명 | 설명 |
|--------|------|
| `etl_transform.py` | Lambda 변환 함수 코드 |
| `test_etl.py` | 테스트 데이터 생성 및 전송 스크립트 |
| `deploy_lambda.sh` | Lambda 함수 배포 자동화 |
| `setup_firehose.sh` | S3, Firehose 인프라 설정 |
| `check_results.sh` | 결과 확인 스크립트 |
| `cleanup.sh` | 리소스 정리 스크립트 |

## 실습 시나리오

### 전체 실행 순서
```bash
# 1. Lambda 함수 배포
cd 2.3.4.src/
bash deploy_lambda.sh

# 2. 인프라 설정 (S3, Firehose)
bash setup_firehose.sh
# 출력된 버킷명을 기록해둠

# 3. 테스트 데이터 전송
python test_etl.py

# 4. 결과 확인 (5-10분 후)
bash check_results.sh <bucket-name>

# 5. 정리
bash cleanup.sh <bucket-name>
```

## 실습 결과 확인

### 성공 기준
- [ ] Lambda 함수가 데이터 변환을 성공적으로 수행
- [ ] 변환된 데이터가 S3에 파티션된 형태로 저장
- [ ] IP 주소 익명화 및 상태 코드 분류 적용
- [ ] 오류 데이터가 별도 경로에 저장
- [ ] CloudWatch에서 메트릭 확인 가능

### 학습 포인트
* **실시간 ETL**: Firehose + Lambda를 통한 스트리밍 데이터 변환
* **데이터 파티셔닝**: 시간 기반 S3 파티션 구조로 쿼리 최적화
* **오류 처리**: 변환 실패 시 별도 경로 저장으로 데이터 손실 방지
* **모니터링**: CloudWatch를 통한 파이프라인 상태 및 성능 추적
* **자동화**: 스크립트를 통한 인프라 설정 및 정리 자동화

## 추가 고려사항

### 운영 환경 적용 시
* Lambda 함수 메모리 및 타임아웃 최적화
* Firehose 버퍼링 설정 조정 (비용 vs 지연시간)
* DLQ(Dead Letter Queue) 설정으로 오류 처리 강화
* VPC 환경에서의 네트워크 설정 고려

이 실습을 통해 기본적인 실시간 ETL 파이프라인을 구축하고 운영하는 방법을 익혔습니다!
