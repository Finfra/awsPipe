# 2.2.1 다양한 소스에서 Kinesis로 데이터 전송

## 개요
실시간 데이터 파이프라인에서는 다양한 소스로부터 데이터를 수집해야 함. 웹 로그, IoT 센서, 데이터베이스 변경 사항, 애플리케이션 이벤트 등 서로 다른 특성을 가진 데이터 소스들을 효율적으로 Kinesis로 통합하는 방법을 다룸.

## 데이터 소스 유형별 전략

### 1. 웹 애플리케이션 로그
웹 서버와 애플리케이션에서 생성되는 로그는 높은 빈도로 발생하며 실시간 처리가 중요함.

#### Apache/Nginx 액세스 로그
웹 서버 로그를 구조화된 데이터로 변환하여 Kinesis로 전송함.

**주요 파싱 필드**
* IP 주소, 타임스탬프, HTTP 메소드
* 요청 경로, 응답 상태 코드, 응답 크기
* 리퍼러, 사용자 에이전트

**사용 예시**
```python
# 로그 라인 예시
log_line = '192.168.1.1 - - [26/May/2024:10:30:45 +0000] "GET /api/users HTTP/1.1" 200 1234'
# → 구조화된 JSON 데이터로 변환
```

### 2. 데이터베이스 변경 데이터 캡처 (CDC)
데이터베이스의 INSERT, UPDATE, DELETE 변경사항을 실시간으로 캡처하여 스트리밍함.

**변경 이벤트 구조**
* 타임스탬프, 데이터베이스명, 테이블명
* 연산 타입(INSERT/UPDATE/DELETE)
* 변경 전/후 데이터
* 트랜잭션 ID

**변경 유형 분류**
* 신규 레코드, 레코드 삭제
* 중요 필드 변경, 일반 업데이트

## 통합 데이터 전송 시스템

### MultiSourceKinesisProducer 아키텍처
다중 소스 데이터를 효율적으로 Kinesis로 전송하는 통합 시스템

**핵심 구성요소**
* **데이터 큐**: 비동기 데이터 수집을 위한 인메모리 큐
* **배치 처리**: 500개 레코드 또는 5초 타임아웃 기준 배치 전송
* **파티션 키 자동 생성**: 데이터 소스별 최적화된 파티셔닝
* **실시간 통계**: 전송 성공/실패, 처리량 모니터링

**데이터 소스별 파티션 키 전략**
* 웹 로그: 세션 ID → IP 주소
* IoT 센서: 디바이스 ID
* 데이터베이스: 테이블명 + 트랜잭션 ID

### 실행 및 통계
```python
# 통계 예시
{
  'total_sent': 15420,
  'total_failed': 23,
  'success_rate': 99.85,
  'throughput_per_sec': 285.3,
  'by_source': {
    'web_logs': {'sent': 8500},
    'iot_sensors': {'sent': 4200},
    'database_cdc': {'sent': 2720}
  }
}
```

## 데이터 변환 및 검증

### 스키마 검증
각 데이터 소스별로 JSON 스키마를 정의하여 데이터 품질을 보장함.

**검증 항목**
* 필수 필드 존재 여부
* 데이터 타입 일치성
* 값 범위 및 형식 검증

**검증 결과 처리**
* 유효한 데이터: Kinesis로 전송
* 무효한 데이터: 에러 로그 기록 및 별도 처리

## 성능 최적화 방법

### 배치 크기 조정
| 배치 크기 | 장점 | 단점 |
| --- | --- | --- |
| 작은 배치 (< 100) | 낮은 지연시간 | 높은 API 호출 비용 |
| 큰 배치 (> 500) | 높은 처리량 | 메모리 사용량 증가 |
| 권장 (500개) | 지연시간과 비용 균형 | 5MB 제한 고려 필요 |

### 파티션 키 최적화
```python
# 최적화된 파티션 키 생성 전략
web_logs: session_id → ip_hash + hour
iot_sensors: device_id + location_hash
database: table_name + transaction_id
```

### 에러 처리 및 재시도
**지수 백오프 재시도**
* 초기 지연: 1초
* 최대 재시도: 3회
* 최대 지연: 60초

## 모니터링 및 알림

### CloudWatch 메트릭
**기본 메트릭**
* RecordsProcessed: 처리된 레코드 수
* RecordsFailed: 실패한 레코드 수
* SuccessRate: 성공률 (%)
* ThroughputPerSec: 초당 처리량

**소스별 메트릭**
* DataSource 차원으로 소스별 성능 추적
* 비정상 소스 조기 감지

### 알람 설정
* 성공률 < 95%: WARNING
* 성공률 < 90%: CRITICAL
* 처리량 급감: ALERT

## 실제 구현 및 실행

> 📁 **완전한 구현 코드**
* [`2.2.1.src/data-sources-integration.py`](2.2.1.src/data-sources-integration.py): 다중 소스 통합 시스템
* [`2.2.1.src/streaming-log-data.py`](2.2.1.src/streaming-log-data.py): 실시간 로그 스트리밍

### 실행 방법
```bash
# 모든 소스 통합 실행
python data-sources-integration.py --stream-name multi-source-stream --duration 300

# 개별 소스 실행
python data-sources-integration.py --stream-name web-logs --source web --duration 300

# 로그 파일 스트리밍
python streaming-log-data.py --stream-name log-stream \
  --log-files '[{"path":"/var/log/apache2/access.log","type":"apache"}]'
```

## 권장사항

### 데이터 소스별 최적화
* **웹 로그**: 로그 파싱 성능 최적화, 세션 기반 파티셔닝
* **IoT 센서**: 디바이스별 배치 처리, 데이터 품질 검증
* **데이터베이스**: 트랜잭션 기반 그룹화, 중요도별 우선순위

### 운영 고려사항
* **백프레셔 처리**: 큐 크기 모니터링 및 제한
* **장애 복구**: DLQ(Dead Letter Queue) 활용
* **스키마 진화**: 하위 호환성 유지
* **비용 최적화**: 배치 크기와 전송 빈도 균형

### 확장성 고려사항
* **수평 확장**: 여러 프로듀서 인스턴스 운영
* **샤드 확장**: Kinesis 스트림 샤드 수 조정
* **부하 분산**: 파티션 키 분산도 최적화
