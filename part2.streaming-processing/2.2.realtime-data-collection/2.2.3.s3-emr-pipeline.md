# 2.2.3. S3/EMR 연동 파이프라인

## 개요
* Kinesis → S3 → EMR로 연결되는 완전한 데이터 파이프라인 구축
* 실시간 스트리밍 데이터를 배치 처리로 연계하는 하이브리드 아키텍처
* S3 기반 데이터 레이크를 중심으로 한 통합 데이터 플랫폼

## 파이프라인 아키텍처

### 전체 데이터 플로우
```
실시간 데이터 → Kinesis → Firehose → S3 (파티션) → EMR (배치처리) → S3 (결과)
                                        ↓
                                   Lambda 트리거
```

### 핵심 구성요소
* **Kinesis Data Streams**: 실시간 데이터 수집
* **Kinesis Data Firehose**: S3로 데이터 전송 및 변환
* **S3**: 데이터 레이크 저장소 (파티션된 구조)
* **EMR**: Spark 기반 배치 처리
* **Lambda**: S3 이벤트 기반 자동 처리 트리거

## S3 데이터 파티셔닝 전략

### 시간 기반 파티셔닝
```
s3://bucket/streaming-data/
├── year=2024/
│   ├── month=01/
│   │   ├── day=15/
│   │   │   ├── hour=00/
│   │   │   ├── hour=01/
│   │   │   └── ...
│   │   └── ...
│   └── ...
```

### 파티션 최적화 전략
* **시간 기반 파티셔닝**: 연/월/일/시간으로 구분
* **압축 형식**: Snappy 또는 GZIP 사용
* **파일 크기**: 128MB-1GB 사이 유지
* **파일 형식**: Parquet (컬럼형 저장)

## EMR 자동 처리 메커니즘

### S3 이벤트 트리거
* **이벤트 유형**: `s3:ObjectCreated:*`
* **필터 조건**: `streaming-data/` 접두사 파일
* **Lambda 함수**: EMR Step 자동 제출

### EMR 클러스터 설정
```python
cluster_config = {
    'ReleaseLabel': 'emr-6.15.0',
    'Applications': ['Spark', 'Hadoop'],
    'Instances': {
        'InstanceGroups': [
            {
                'Name': 'Master',
                'InstanceRole': 'MASTER',
                'InstanceType': 'm5.xlarge',
                'InstanceCount': 1
            },
            {
                'Name': 'Core', 
                'InstanceRole': 'CORE',
                'InstanceType': 'm5.large',
                'InstanceCount': 2
            }
        ]
    },
    'AutoTerminationPolicy': {
        'IdleTimeout': 14400  # 4시간
    }
}
```

## Spark 처리 로직

### 실시간 집계 처리
* **사용자별 활동 요약**
    - 총 이벤트 수, 세션 수
    - 총 가치합, 평균값
    - 마지막 활동 시간
* **시간별 트렌드 분석**
    - 시간대별 이벤트 수
    - 유니크 사용자 수
    - 총 가치 합계
* **이상값 탐지**
    - Z-score 기반 이상값 탐지 (임계값: 3)
    - 이상값 레코드 별도 저장

### 결과 데이터 구조
```
s3://bucket/processed-data/
├── year=2024/month=01/day=15/hour=10/
│   ├── user-activity/
│   ├── hourly-trends/
│   └── anomalies/
```

## 모니터링 및 알람

### CloudWatch 메트릭
* **Kinesis**: IncomingRecords, IncomingBytes
* **Firehose**: DeliveryToS3.Records, DeliveryToS3.Success  
* **EMR**: StepsRunning, StepsFailed, AppsCompleted
* **Lambda**: Duration, Errors, Throttles

### 알람 설정
* EMR Step 실패 시 즉시 알림
* Kinesis 처리량 급증 시 알림
* Firehose 전송 실패율 임계값 초과 시 알림

## 데이터 품질 관리

### 데이터 검증
* **스키마 검증**: 필수 필드 존재 확인
* **타입 검증**: 적절한 데이터 타입 확인
* **범위 검증**: 값의 유효 범위 확인

### 오류 처리
* **변환 실패**: 별도 에러 파티션에 저장
* **스키마 불일치**: Dead Letter Queue 활용
* **재처리**: 실패한 배치 수동 재실행 지원

## 성능 최적화

### Spark 최적화
* **적응형 쿼리 실행**: `spark.sql.adaptive.enabled=true`
* **동적 파티션 병합**: `spark.sql.adaptive.coalescePartitions.enabled=true`
* **S3 멀티파트 업로드**: 128MB 청크 크기
* **Parquet 압축**: Snappy 코덱 사용

### 비용 최적화
* **스팟 인스턴스**: Core 노드에 스팟 인스턴스 활용
* **자동 종료**: 유휴 시간 후 클러스터 자동 종료
* **S3 스토리지 클래스**: 오래된 데이터는 IA/Glacier로 전환

## 보안 설정

### IAM 역할 권한
* **EMR 서비스 역할**: EMR_DefaultRole
* **EC2 인스턴스 프로파일**: EMR_EC2_DefaultRole  
* **Firehose 전송 역할**: S3 쓰기 권한
* **Lambda 실행 역할**: EMR 작업 제출 권한

### 데이터 암호화
* **전송 중 암호화**: HTTPS/TLS
* **저장 중 암호화**: S3 KMS 암호화
* **네트워크 보안**: VPC 내 프라이빗 서브넷 활용

## 운영 가이드

### 배포 프로세스
```bash
# 1. Spark 스크립트 업로드
aws s3 cp streaming_processor.py s3://bucket/scripts/

# 2. EMR 클러스터 생성
aws emr create-cluster --cli-input-json cluster-config.json

# 3. Lambda 함수 배포
aws lambda create-function --function-name s3-emr-trigger

# 4. S3 이벤트 알림 설정
aws s3api put-bucket-notification-configuration
```

### 장애 대응
* **EMR 클러스터 장애**: 자동 재시작 또는 새 클러스터 생성
* **S3 접근 실패**: IAM 권한 및 네트워크 연결 확인
* **Lambda 함수 오류**: CloudWatch 로그 확인 후 수정 배포

### 성능 튜닝
* **파티션 수 조정**: 데이터 볼륨에 따른 동적 조정
* **인스턴스 타입**: 워크로드 특성에 맞는 인스턴스 선택
* **배치 크기**: 처리량과 지연시간 균형점 찾기

## 참고 자료
* [EMR Spark 최적화](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-performance.html)
* [Kinesis Data Firehose](https://docs.aws.amazon.com/kinesis/latest/dev/what-is-this-service.html)
* [S3 파티셔닝 모범 사례](https://docs.aws.amazon.com/athena/latest/ug/partitions.html)
