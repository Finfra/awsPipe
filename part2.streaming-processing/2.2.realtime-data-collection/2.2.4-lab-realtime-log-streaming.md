# 2.2.4. ì‹¤ìŠµ: ì‹¤ì‹œê°„ ë¡œê·¸ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°

## ì‹¤ìŠµ ëª©í‘œ
* ì›¹ ì„œë²„ ë¡œê·¸ì™€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ Kinesisë¡œ ì „ì†¡
* ë‹¤ì–‘í•œ ë¡œê·¸ í˜•ì‹ íŒŒì‹± ë° í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
* ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ì¸¡ì •

## ì‚¬ì „ ì¤€ë¹„

### í•„ìš”í•œ ì†ŒìŠ¤ íŒŒì¼
> ğŸ“ **ì‹¤ìŠµ ì†ŒìŠ¤ ì½”ë“œ**: [`2.2.1.src/streaming-log-data.py`](../2.2.1.src/streaming-log-data.py)

### í•„ìš”í•œ AWS ì„œë¹„ìŠ¤
* **Kinesis Data Streams**: ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì§‘
* **EC2 ì¸ìŠ¤í„´ìŠ¤**: ë¡œê·¸ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ì—ì´ì „íŠ¸ ì‹¤í–‰
* **CloudWatch**: ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

### ë¡œì»¬ í™˜ê²½ ì„¤ì •
```bash
# Python ì˜ì¡´ì„± ì„¤ì¹˜
pip install boto3 

# AWS CLI ì„¤ì • í™•ì¸
aws configure list
aws kinesis list-streams
```

## Step 1: Kinesis ìŠ¤íŠ¸ë¦¼ ìƒì„±

### ìŠ¤íŠ¸ë¦¼ ìƒì„±
```bash
# ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ìš© Kinesis ìŠ¤íŠ¸ë¦¼ ìƒì„±
aws kinesis create-stream \
    --stream-name log-streaming-demo \
    --shard-count 2

# ìŠ¤íŠ¸ë¦¼ ìƒíƒœ í™•ì¸
aws kinesis describe-stream \
    --stream-name log-streaming-demo
```

### ìŠ¤íŠ¸ë¦¼ í™œì„±í™” ëŒ€ê¸°
```bash
# ìŠ¤íŠ¸ë¦¼ì´ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
while [ "$(aws kinesis describe-stream --stream-name log-streaming-demo --query 'StreamDescription.StreamStatus' --output text)" != "ACTIVE" ]; do
    echo "ìŠ¤íŠ¸ë¦¼ í™œì„±í™” ëŒ€ê¸° ì¤‘..."
    sleep 10
done
echo "ìŠ¤íŠ¸ë¦¼ ì¤€ë¹„ ì™„ë£Œ!"
```

## Step 2: ë¡œê·¸ íŒŒì¼ ì¤€ë¹„

### í…ŒìŠ¤íŠ¸ ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
```bash
mkdir -p /tmp/streaming-logs/{apache,nginx,application}
```

### Apache ë¡œê·¸ í˜•ì‹ ì˜ˆì‹œ
```bash
# /tmp/streaming-logs/apache/access.log
192.168.1.100 - - [15/Jan/2024:10:30:45 +0000] "GET /index.html HTTP/1.1" 200 2435 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
10.0.0.50 - - [15/Jan/2024:10:30:46 +0000] "POST /api/users HTTP/1.1" 201 156 "https://example.com/signup" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
```

### Nginx ë¡œê·¸ í˜•ì‹ ì˜ˆì‹œ
```bash
# /tmp/streaming-logs/nginx/access.log  
192.168.1.101 - - [15/Jan/2024:10:31:00 +0000] "GET /api/orders HTTP/1.1" 200 1024 "https://app.example.com" "curl/7.68.0"
203.0.113.10 - - [15/Jan/2024:10:31:01 +0000] "DELETE /api/orders/123 HTTP/1.1" 204 0 "-" "axios/0.21.1"
```

### ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ í˜•ì‹ (JSON)
```bash
# /tmp/streaming-logs/application/app.log
{"timestamp": "2024-01-15T10:30:45.123Z", "level": "INFO", "logger": "com.example.UserService", "message": "User login successful", "user_id": 12345, "request_id": "req-001"}
{"timestamp": "2024-01-15T10:30:46.456Z", "level": "WARN", "logger": "com.example.OrderService", "message": "Order processing delayed", "order_id": 67890, "request_id": "req-002"}
```

## Step 3: ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰

### ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
```bash
# ë¡œê·¸ íŒŒì¼ ì„¤ì •
LOG_CONFIG='[
    {
        "path": "/tmp/streaming-logs/apache/access.log",
        "type": "apache"
    },
    {
        "path": "/tmp/streaming-logs/nginx/access.log", 
        "type": "nginx"
    },
    {
        "path": "/tmp/streaming-logs/application/app.log",
        "type": "application"
    }
]'

# ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰ (2.2.1.src ë””ë ‰í† ë¦¬ì—ì„œ)
cd ../2.2.1.src/
python streaming-log-data.py \
    --stream-name log-streaming-demo \
    --region us-east-1 \
    --log-files "$LOG_CONFIG"
```

### í…ŒìŠ¤íŠ¸ ë¡œê·¸ ìƒì„±ê³¼ í•¨ê»˜ ì‹¤í–‰
```bash
# í…ŒìŠ¤íŠ¸ ë¡œê·¸ ìë™ ìƒì„± ëª¨ë“œ
cd ../2.2.1.src/
python streaming-log-data.py \
    --stream-name log-streaming-demo \
    --region us-east-1 \
    --log-files "$LOG_CONFIG" \
    --generate-test-logs
```

## Step 4: ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§

### Kinesis ë ˆì½”ë“œ í™•ì¸
```bash
# ìŠ¤íŠ¸ë¦¼ì—ì„œ ë ˆì½”ë“œ ì½ê¸°
SHARD_ITERATOR=$(aws kinesis get-shard-iterator \
    --stream-name log-streaming-demo \
    --shard-id shardId-000000000000 \
    --shard-iterator-type LATEST \
    --query 'ShardIterator' --output text)

# ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸°
aws kinesis get-records \
    --shard-iterator $SHARD_ITERATOR \
    --query 'Records[*].Data' \
    --output text | base64 -d
```

### CloudWatch ë©”íŠ¸ë¦­ í™•ì¸
```bash
# Kinesis ìŠ¤íŠ¸ë¦¼ ë©”íŠ¸ë¦­ ì¡°íšŒ
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=log-streaming-demo \
    --start-time $(date -u -d '10 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Sum
```

## Step 5: ë¡œê·¸ íŒŒì‹± ê²€ì¦

### íŒŒì‹±ëœ ë°ì´í„° êµ¬ì¡° í™•ì¸
```python
# Pythonì—ì„œ ì§ì ‘ í™•ì¸
import json

# Apache ë¡œê·¸ íŒŒì‹± ê²°ê³¼ ì˜ˆì‹œ
apache_parsed = {
    'timestamp': '2024-01-15T10:30:45+00:00',
    'ip_address': '192.168.1.100',
    'method': 'GET',
    'path': '/index.html',
    'protocol': 'HTTP/1.1',
    'status_code': 200,
    'response_size': 2435,
    'referer': None,
    'user_agent': 'Mozilla/5.0...',
    'log_type': 'apache_access'
}

print(json.dumps(apache_parsed, indent=2))
```

### ë¡œê·¸ íƒ€ì…ë³„ í•„ë“œ ë§¤í•‘

| ë¡œê·¸ íƒ€ì…   | ê³µí†µ í•„ë“œ                       | íŠ¹í™” í•„ë“œ                                   |
| ----------- | ------------------------------- | ------------------------------------------- |
| Apache      | timestamp, ip_address, log_type | method, path, status_code, response_size    |
| Nginx       | timestamp, ip_address, log_type | method, path, status_code, response_size    |
| Application | timestamp, log_type             | level, logger, message, user_id, request_id |

## Step 6: ì„±ëŠ¥ ì¸¡ì • ë° ìµœì í™”

### ìŠ¤íŠ¸ë¦¬ë° í†µê³„ í™•ì¸
```bash
# ìŠ¤íŠ¸ë¦¬ë° ì¤‘ í†µê³„ ë¡œê·¸ ì˜ˆì‹œ
=== ìŠ¤íŠ¸ë¦¬ë° í†µê³„ ===
ì²˜ë¦¬ëœ ë¼ì¸: 1,250
ì „ì†¡ëœ ë ˆì½”ë“œ: 1,180
ì˜¤ë¥˜: 12
ì²˜ë¦¬ìœ¨: 25.3 ë¼ì¸/ì´ˆ
ì „ì†¡ìœ¨: 23.8 ë ˆì½”ë“œ/ì´ˆ
í í¬ê¸°: 15
```

### ì„±ëŠ¥ íŠœë‹ íŒŒë¼ë¯¸í„°
```python
# streaming-log-data.py ì„¤ì • ìµœì í™”
streamer_config = {
    'batch_size': 500,        # ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 500)
    'batch_timeout': 5,       # ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    'queue_maxsize': 1000,    # ë‚´ë¶€ í ìµœëŒ€ í¬ê¸°
    'parse_workers': 4        # íŒŒì‹± ì›Œì»¤ ìŠ¤ë ˆë“œ ìˆ˜
}
```

## Step 7: ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ìƒí™©
* **íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ ì˜¤ë¥˜**
    ```bash
    chmod 644 /tmp/streaming-logs/*/access.log
    ```
* **AWS ê¶Œí•œ ì˜¤ë¥˜**
    ```bash
    # Kinesis ê¶Œí•œ í™•ì¸
    aws iam get-user-policy --user-name streaming-user --policy-name KinesisAccess
    ```
* **ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜**
    ```bash
    # AWS ì—°ê²° í…ŒìŠ¤íŠ¸
    aws kinesis list-streams --region us-east-1
    ```

### ì¬ì‹œì‘ ë° ë³µêµ¬
```bash
# ìŠ¤íŠ¸ë¦¬ë¨¸ í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
pkill -f streaming-log-data.py

# ì•ˆì „í•œ ì¬ì‹œì‘
cd ../2.2.1.src/
python streaming-log-data.py \
    --stream-name log-streaming-demo \
    --log-files "$LOG_CONFIG" \
    --resume-from-checkpoint
```

## Step 8: ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦

### Kinesis Analyticsë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì§‘ê³„
```sql
-- ì‹¤ì‹œê°„ ì§‘ê³„ ì¿¼ë¦¬ ì˜ˆì‹œ
CREATE STREAM aggregated_logs AS 
SELECT 
    log_type,
    COUNT(*) as event_count,
    COUNT(DISTINCT ip_address) as unique_ips,
    AVG(response_size) as avg_response_size
FROM SOURCE_SQL_STREAM_001
WHERE log_type IS NOT NULL
GROUP BY log_type, 
         ROWTIME RANGE INTERVAL '1' MINUTE;
```

### ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë°ì´í„°
* **ì´ˆë‹¹ ë¡œê·¸ ì²˜ë¦¬ëŸ‰**: í‰ê·  25-30 ë¼ì¸/ì´ˆ
* **íŒŒì‹± ì„±ê³µë¥ **: 95% ì´ìƒ
* **ì „ì†¡ ì§€ì—°ì‹œê°„**: í‰ê·  2-3ì´ˆ
* **ì˜¤ë¥˜ìœ¨**: 1% ë¯¸ë§Œ

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### íŒŒì‹± ì‹¤íŒ¨ ë¬¸ì œ
```python
# íŒŒì‹± ì‹¤íŒ¨í•œ ë¡œê·¸ ë¼ì¸ ë””ë²„ê¹…
def debug_parsing_failure(log_line, log_type):
    print(f"Failed to parse {log_type} log: {log_line}")
    # ì •ê·œì‹ íŒ¨í„´ í™•ì¸
    # ë¡œê·¸ í˜•ì‹ ë§ëŠ”ì§€ ê²€ì¦
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ íŒŒì¼ ì½ê¸°
def efficient_tail_file(file_path):
    # ë²„í¼ í¬ê¸° ì¡°ì •
    # í í¬ê¸° ì œí•œ
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”
```

### ë°°ì¹˜ ì „ì†¡ ìµœì í™”
```python
# ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •
def adaptive_batch_size():
    # ì²˜ë¦¬ëŸ‰ ê¸°ë°˜ ë™ì  ì¡°ì •
    # ì§€ì—°ì‹œê°„ ì„ê³„ê°’ ê´€ë¦¬
    # ì˜¤ë¥˜ìœ¨ ê¸°ë°˜ ë°±ì˜¤í”„
```

## ì‹¤ìŠµ ê²°ê³¼ í™•ì¸

### ì„±ê³µ ê¸°ì¤€
- [ ] 3ê°€ì§€ ë¡œê·¸ íƒ€ì… ëª¨ë‘ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±
- [ ] Kinesisì— ì´ˆë‹¹ 20ê°œ ì´ìƒ ë ˆì½”ë“œ ì „ì†¡  
- [ ] íŒŒì‹± ì„±ê³µë¥  95% ì´ìƒ ë‹¬ì„±
- [ ] ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ë™ì‘ í™•ì¸

### ì¶”ê°€ ì‹¤ìŠµ ê³¼ì œ
* **ë¡œê·¸ ë¡œí…Œì´ì…˜ ì²˜ë¦¬**: logrotateì™€ ì—°ë™í•˜ì—¬ ë¡œê·¸ íŒŒì¼ íšŒì „ ì²˜ë¦¬
* **ë‹¤ì¤‘ ì„œë²„ ë¡œê·¸**: ì—¬ëŸ¬ ì„œë²„ì˜ ë¡œê·¸ë¥¼ í†µí•© ìŠ¤íŠ¸ë¦¬ë°
* **ì‹¤ì‹œê°„ ì•ŒëŒ**: íŠ¹ì • ë¡œê·¸ íŒ¨í„´ ê°ì§€ ì‹œ ì¦‰ì‹œ ì•Œë¦¼

## ì •ë¦¬ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬

### ë¦¬ì†ŒìŠ¤ ì •ë¦¬
```bash
# Kinesis ìŠ¤íŠ¸ë¦¼ ì‚­ì œ
aws kinesis delete-stream --stream-name log-streaming-demo

# í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
rm -rf /tmp/streaming-logs

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
pkill -f streaming-log-data.py
```

### ë‹¤ìŒ ë‹¨ê³„
* **2.2.5 ì‹¤ìŠµ**: Kinesis â†’ S3 â†’ EMR íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
* **2.3.1**: Kinesis Data Firehose ë³€í™˜ ê¸°ëŠ¥ í™œìš©
* **3.2**: CloudWatch ê¸°ë°˜ ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì„¤ì •
