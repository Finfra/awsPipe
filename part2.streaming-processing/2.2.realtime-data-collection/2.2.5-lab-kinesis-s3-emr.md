# 2.2.5. 실습: Kinesis → S3 → EMR 파이프라인 구축

## 실습 목표
* Kinesis Data Firehose를 통한 S3 자동 저장 설정
* S3 이벤트 기반 EMR 자동 처리 파이프라인 구축
* 실시간 스트리밍 데이터의 배치 처리 및 분석
* 완전 자동화된 데이터 파이프라인 운영

## 사전 준비

### 필요한 AWS 서비스
* **Kinesis Data Streams**: 실시간 데이터 수집
* **Kinesis Data Firehose**: S3 자동 전송
* **S3**: 데이터 레이크 저장소
* **EMR**: Spark 배치 처리
* **Lambda**: S3 이벤트 트리거
* **CloudWatch**: 모니터링 및 알람

### IAM 역할 준비
```bash
# Firehose 전송 역할 생성
aws iam create-role \
    --role-name FirehoseDeliveryRole \
    --assume-role-policy-document '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "firehose.amazonaws.com"},
            "Action": "sts:AssumeRole"
        }]
    }'

# S3 쓰기 권한 정책 연결
aws iam attach-role-policy \
    --role-name FirehoseDeliveryRole \
    --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
```

## Step 1: S3 버킷 및 구조 설정

### 데이터 레이크 버킷 생성
```bash
# 고유한 버킷 이름으로 생성
BUCKET_NAME="streaming-pipeline-$(date +%s)"
aws s3 mb s3://$BUCKET_NAME --region us-east-1

# 버킷 정책 설정 (선택사항)
aws s3api put-bucket-policy \
    --bucket $BUCKET_NAME \
    --policy '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "firehose.amazonaws.com"},
            "Action": ["s3:PutObject", "s3:GetObject", "s3:ListBucket"],
            "Resource": ["arn:aws:s3:::'"$BUCKET_NAME"'/*", "arn:aws:s3:::'"$BUCKET_NAME"'"]
        }]
    }'
```

### 폴더 구조 생성
```bash
# 기본 폴더 구조 생성
aws s3 cp /dev/null s3://$BUCKET_NAME/scripts/
aws s3 cp /dev/null s3://$BUCKET_NAME/streaming-data/
aws s3 cp /dev/null s3://$BUCKET_NAME/processed-data/
aws s3 cp /dev/null s3://$BUCKET_NAME/emr-logs/
```

## Step 2: Kinesis Data Firehose 설정

### Firehose 전송 스트림 생성
```bash
# 전송 스트림 설정
cat > firehose-config.json << 'EOF'
{
    "DeliveryStreamName": "streaming-to-s3-pipeline",
    "DeliveryStreamType": "KinesisStreamAsSource",
    "KinesisStreamSourceConfiguration": {
        "KinesisStreamARN": "arn:aws:kinesis:us-east-1:ACCOUNT_ID:stream/log-streaming-demo",
        "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole"
    },
    "ExtendedS3DestinationConfiguration": {
        "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole",
        "BucketARN": "arn:aws:s3:::BUCKET_NAME",
        "Prefix": "streaming-data/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/hour=!{timestamp:HH}/",
        "ErrorOutputPrefix": "streaming-errors/",
        "BufferingHints": {
            "SizeInMBs": 128,
            "IntervalInSeconds": 300
        },
        "CompressionFormat": "SNAPPY",
        "DataFormatConversionConfiguration": {
            "Enabled": true,
            "OutputFormatConfiguration": {
                "Serializer": {
                    "ParquetSerDe": {}
                }
            },
            "SchemaConfiguration": {
                "DatabaseName": "streaming_db",
                "TableName": "log_events",
                "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole"
            }
        },
        "CloudWatchLoggingOptions": {
            "Enabled": true,
            "LogGroupName": "/aws/kinesisfirehose/streaming-to-s3-pipeline"
        }
    }
}
EOF

# 계정 ID와 버킷 이름 치환
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
sed -i "s/ACCOUNT_ID/$ACCOUNT_ID/g" firehose-config.json
sed -i "s/BUCKET_NAME/$BUCKET_NAME/g" firehose-config.json

# Firehose 스트림 생성
aws firehose create-delivery-stream \
    --cli-input-json file://firehose-config.json
```

### Firehose 상태 확인
```bash
# 생성 상태 모니터링
while [ "$(aws firehose describe-delivery-stream --delivery-stream-name streaming-to-s3-pipeline --query 'DeliveryStreamDescription.DeliveryStreamStatus' --output text)" != "ACTIVE" ]; do
    echo "Firehose 스트림 생성 중..."
    sleep 30
done
echo "Firehose 스트림 준비 완료!"
```

## Step 3: EMR 클러스터 생성

### 클러스터 설정 파일 생성
```bash
cat > emr-cluster-config.json << 'EOF'
{
    "Name": "streaming-processing-cluster",
    "ReleaseLabel": "emr-6.15.0",
    "Applications": [
        {"Name": "Spark"},
        {"Name": "Hadoop"},
        {"Name": "Hive"}
    ],
    "Instances": {
        "InstanceGroups": [
            {
                "Name": "Master",
                "Market": "ON_DEMAND",
                "InstanceRole": "MASTER",
                "InstanceType": "m5.xlarge",
                "InstanceCount": 1
            },
            {
                "Name": "Core",
                "Market": "SPOT",
                "BidPrice": "0.20",
                "InstanceRole": "CORE",
                "InstanceType": "m5.large",
                "InstanceCount": 2
            }
        ],
        "KeepJobFlowAliveWhenNoSteps": true,
        "TerminationProtected": false
    },
    "ServiceRole": "EMR_DefaultRole",
    "JobFlowRole": "EMR_EC2_DefaultRole",
    "LogUri": "s3://BUCKET_NAME/emr-logs/",
    "Configurations": [
        {
            "Classification": "spark-defaults",
            "Properties": {
                "spark.sql.adaptive.enabled": "true",
                "spark.sql.adaptive.coalescePartitions.enabled": "true",
                "spark.hadoop.fs.s3a.multipart.size": "134217728",
                "spark.sql.parquet.compression.codec": "snappy",
                "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
            }
        }
    ],
    "AutoTerminationPolicy": {
        "IdleTimeout": 14400
    },
    "Tags": [
        {"Key": "Project", "Value": "StreamingPipeline"},
        {"Key": "Environment", "Value": "Demo"}
    ]
}
EOF

# 버킷 이름 치환
sed -i "s/BUCKET_NAME/$BUCKET_NAME/g" emr-cluster-config.json

# EMR 클러스터 생성
CLUSTER_ID=$(aws emr create-cluster \
    --cli-input-json file://emr-cluster-config.json \
    --query 'JobFlowId' --output text)

echo "EMR 클러스터 생성됨: $CLUSTER_ID"
```

### 클러스터 준비 대기
```bash
# 클러스터 WAITING 상태까지 대기
echo "EMR 클러스터 준비 대기 중..."
while [ "$(aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --output text)" != "WAITING" ]; do
    STATE=$(aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --output text)
    echo "현재 상태: $STATE"
    if [ "$STATE" = "TERMINATED" ] || [ "$STATE" = "TERMINATED_WITH_ERRORS" ]; then
        echo "클러스터 생성 실패!"
        exit 1
    fi
    sleep 60
done
echo "EMR 클러스터 준비 완료!"
```

## Step 4: Spark 처리 스크립트 업로드

### 데이터 처리 스크립트 생성 및 업로드
```bash
# 이미 생성된 streaming_processor.py를 S3에 업로드
aws s3 cp streaming_processor.py s3://$BUCKET_NAME/scripts/

# 실행 권한 확인
aws s3api head-object --bucket $BUCKET_NAME --key scripts/streaming_processor.py
```

## Step 5: Lambda 트리거 함수 생성

### Lambda 함수 패키징 및 배포
```bash
# 이미 생성된 Lambda 함수 코드를 패키징
zip s3-emr-trigger.zip s3_emr_trigger.py

# Lambda 실행 역할 생성
aws iam create-role \
    --role-name lambda-s3-emr-trigger-role \
    --assume-role-policy-document '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "lambda.amazonaws.com"},
            "Action": "sts:AssumeRole"
        }]
    }' || true

# 필요한 정책 연결
aws iam attach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

aws iam attach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/ElasticMapReduceFullAccess

# Lambda 함수 생성
LAMBDA_ROLE_ARN="arn:aws:iam::$ACCOUNT_ID:role/lambda-s3-emr-trigger-role"

aws lambda create-function \
    --function-name s3-emr-trigger \
    --runtime python3.9 \
    --role $LAMBDA_ROLE_ARN \
    --handler s3_emr_trigger.lambda_handler \
    --zip-file fileb://s3-emr-trigger.zip \
    --timeout 300 \
    --environment Variables="{EMR_CLUSTER_ID=$CLUSTER_ID}" \
    --tags Project=StreamingPipeline,Environment=Demo
```

### S3 이벤트 알림 설정
```bash
# S3 이벤트 알림 설정
LAMBDA_ARN="arn:aws:lambda:us-east-1:$ACCOUNT_ID:function:s3-emr-trigger"

# Lambda 함수에 S3 호출 권한 부여
aws lambda add-permission \
    --function-name s3-emr-trigger \
    --principal s3.amazonaws.com \
    --action lambda:InvokeFunction \
    --statement-id s3-trigger-permission \
    --source-arn arn:aws:s3:::$BUCKET_NAME

# S3 이벤트 알림 설정
aws s3api put-bucket-notification-configuration \
    --bucket $BUCKET_NAME \
    --notification-configuration '{
        "LambdaConfigurations": [{
            "Id": "emr-trigger-notification",
            "LambdaFunctionArn": "'$LAMBDA_ARN'",
            "Events": ["s3:ObjectCreated:*"],
            "Filter": {
                "Key": {
                    "FilterRules": [{
                        "Name": "prefix",
                        "Value": "streaming-data/"
                    }]
                }
            }
        }]
    }'
```

## Step 6: 파이프라인 테스트

### 테스트 데이터 전송
```bash
# 테스트 스크립트 실행
python test_pipeline.py
```

### 파이프라인 진행 상황 모니터링
```bash
# Firehose 스트림 상태 확인
aws firehose describe-delivery-stream \
    --delivery-stream-name streaming-to-s3-pipeline \
    --query 'DeliveryStreamDescription.DeliveryStreamStatus'

# S3에 데이터 도착 확인 (5-10분 후)
echo "S3 데이터 확인 중..."
aws s3 ls s3://$BUCKET_NAME/streaming-data/ --recursive

# EMR Step 상태 확인
echo "EMR 작업 상태 확인..."
aws emr list-steps --cluster-id $CLUSTER_ID \
    --query 'Steps[*].{Name:Name,State:Status.State,CreationDateTime:Status.Timeline.CreationDateTime}'
```

## Step 7: 결과 데이터 확인

### 처리 결과 조회
```bash
# 처리된 데이터 확인
echo "처리된 데이터 확인..."
aws s3 ls s3://$BUCKET_NAME/processed-data/ --recursive

# 결과 데이터 다운로드 및 확인
mkdir -p ./pipeline-results
aws s3 sync s3://$BUCKET_NAME/processed-data/ ./pipeline-results/

# Parquet 파일 내용 확인
pip install pandas pyarrow
python check_results.py
```

## Step 8: 모니터링 및 알람 설정

### CloudWatch 대시보드 생성
```bash
cat > dashboard-config.json << 'EOF'
{
    "widgets": [
        {
            "type": "metric",
            "properties": {
                "metrics": [
                    ["AWS/Kinesis", "IncomingRecords", "StreamName", "log-streaming-demo"],
                    ["AWS/KinesisFirehose", "DeliveryToS3.Records", "DeliveryStreamName", "streaming-to-s3-pipeline"]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "us-east-1",
                "title": "데이터 처리량"
            }
        },
        {
            "type": "metric", 
            "properties": {
                "metrics": [
                    ["AWS/ElasticMapReduce", "StepsRunning", "JobFlowId", "CLUSTER_ID"],
                    ["AWS/ElasticMapReduce", "StepsCompleted", "JobFlowId", "CLUSTER_ID"],
                    ["AWS/ElasticMapReduce", "StepsFailed", "JobFlowId", "CLUSTER_ID"]
                ],
                "period": 300,
                "stat": "Average",
                "region": "us-east-1", 
                "title": "EMR 작업 상태"
            }
        }
    ]
}
EOF

# 클러스터 ID 치환
sed -i "s/CLUSTER_ID/$CLUSTER_ID/g" dashboard-config.json

# 대시보드 생성
aws cloudwatch put-dashboard \
    --dashboard-name "StreamingPipelineDashboard" \
    --dashboard-body file://dashboard-config.json
```

### 알람 설정
```bash
# EMR Step 실패 알람
aws cloudwatch put-metric-alarm \
    --alarm-name "EMR-Steps-Failed" \
    --alarm-description "EMR steps failed alarm" \
    --metric-name StepsFailed \
    --namespace AWS/ElasticMapReduce \
    --statistic Sum \
    --period 300 \
    --threshold 0 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 1 \
    --dimensions Name=JobFlowId,Value=$CLUSTER_ID

# Firehose 전송 오류 알람
aws cloudwatch put-metric-alarm \
    --alarm-name "Firehose-Delivery-Errors" \
    --alarm-description "Firehose delivery errors" \
    --metric-name DeliveryToS3.DataFreshness \
    --namespace AWS/KinesisFirehose \
    --statistic Maximum \
    --period 300 \
    --threshold 3600 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 2 \
    --dimensions Name=DeliveryStreamName,Value=streaming-to-s3-pipeline
```

## Step 9: 성능 최적화 및 튜닝

### Firehose 배치 설정 최적화
```bash
# 더 자주 전송하도록 설정 수정
aws firehose update-destination \
    --delivery-stream-name streaming-to-s3-pipeline \
    --version-id 1 \
    --destination-id destinationId-000000000001 \
    --extended-s3-destination-update '{
        "BufferingHints": {
            "SizeInMBs": 64,
            "IntervalInSeconds": 180
        }
    }'
```

### EMR 클러스터 자동 스케일링
```bash
# 자동 스케일링 정책 추가
aws emr put-auto-scaling-policy \
    --cluster-id $CLUSTER_ID \
    --instance-group-id ig-XXXXXXXXXX \
    --auto-scaling-policy '{
        "Constraints": {
            "MinCapacity": 2,
            "MaxCapacity": 10
        },
        "Rules": [{
            "Name": "ScaleOutMemoryPercentage",
            "Description": "Scale out if YARNMemoryAvailablePercentage is less than 15",
            "Action": {
                "Market": "ON_DEMAND",
                "SimpleScalingPolicyConfiguration": {
                    "AdjustmentType": "CHANGE_IN_CAPACITY",
                    "ScalingAdjustment": 1,
                    "CoolDown": 300
                }
            },
            "Trigger": {
                "CloudWatchAlarmDefinition": {
                    "ComparisonOperator": "LESS_THAN_OR_EQUAL",
                    "EvaluationPeriods": 1,
                    "MetricName": "YARNMemoryAvailablePercentage",
                    "Namespace": "AWS/ElasticMapReduce",
                    "Period": 300,
                    "Statistic": "AVERAGE",
                    "Threshold": 15.0,
                    "Unit": "PERCENT"
                }
            }
        }]
    }'
```

## Step 10: 문제 해결 및 디버깅

### 일반적인 문제 해결

#### Firehose 전송 실패
```bash
# Firehose 로그 확인
aws logs describe-log-groups \
    --log-group-name-prefix "/aws/kinesisfirehose/"

aws logs get-log-events \
    --log-group-name "/aws/kinesisfirehose/streaming-to-s3-pipeline" \
    --log-stream-name "S3Delivery"
```

#### Lambda 함수 오류
```bash
# Lambda 함수 로그 확인
aws logs describe-log-groups \
    --log-group-name-prefix "/aws/lambda/s3-emr-trigger"

aws logs get-log-events \
    --log-group-name "/aws/lambda/s3-emr-trigger" \
    --log-stream-name "최신_로그_스트림_이름"
```

#### EMR Step 실패
```bash
# EMR Step 상세 정보 확인
STEP_ID=$(aws emr list-steps --cluster-id $CLUSTER_ID --query 'Steps[0].Id' --output text)

aws emr describe-step \
    --cluster-id $CLUSTER_ID \
    --step-id $STEP_ID

# EMR 로그 확인
aws s3 ls s3://$BUCKET_NAME/emr-logs/ --recursive
```

### 성능 모니터링 쿼리
```bash
# Kinesis 처리량 확인
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=log-streaming-demo \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Sum

# EMR 리소스 사용률 확인
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElasticMapReduce \
    --metric-name YARNMemoryAvailablePercentage \
    --dimensions Name=JobFlowId,Value=$CLUSTER_ID \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average
```

## 실습 결과 확인

### 성공 기준
- [ ] Kinesis → Firehose → S3 데이터 흐름 정상 동작
- [ ] S3 파티션 구조 올바르게 생성 (year/month/day/hour)
- [ ] Lambda 트리거를 통한 EMR 자동 실행
- [ ] Spark 작업 성공적 완료 및 결과 데이터 생성
- [ ] CloudWatch 모니터링 및 알람 정상 동작

### 기대 결과
* **데이터 지연시간**: 5-10분 (Firehose 버퍼링 + EMR 처리)
* **처리 성공률**: 95% 이상
* **자동화 수준**: 완전 자동 (수동 개입 불필요)
* **비용 효율성**: 스팟 인스턴스 활용으로 30-50% 절약

## 정리 및 리소스 정리

### 실습 완료 후 정리
```bash
# EMR 클러스터 종료
aws emr terminate-clusters --cluster-ids $CLUSTER_ID

# Lambda 함수 삭제
aws lambda delete-function --function-name s3-emr-trigger

# Firehose 스트림 삭제
aws firehose delete-delivery-stream \
    --delivery-stream-name streaming-to-s3-pipeline

# S3 버킷 내용 삭제 후 버킷 삭제
aws s3 rm s3://$BUCKET_NAME --recursive
aws s3 rb s3://$BUCKET_NAME

# CloudWatch 대시보드 삭제
aws cloudwatch delete-dashboards \
    --dashboard-names StreamingPipelineDashboard

# CloudWatch 알람 삭제
aws cloudwatch delete-alarms \
    --alarm-names EMR-Steps-Failed Firehose-Delivery-Errors

# IAM 역할 정리
aws iam detach-role-policy \
    --role-name FirehoseDeliveryRole \
    --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
aws iam delete-role --role-name FirehoseDeliveryRole

aws iam detach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
aws iam detach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/ElasticMapReduceFullAccess
aws iam delete-role --role-name lambda-s3-emr-trigger-role
```

## 다음 단계
* **2.3.1**: Kinesis Data Firehose 변환 기능 심화
* **2.3.4**: 실시간 ETL 파이프라인 구현
* **3.2**: CloudWatch 기반 통합 모니터링 구축

## 참고 자료
* [Kinesis Data Firehose 개발자 가이드](https://docs.aws.amazon.com/kinesis/latest/dev/)
* [EMR Spark 최적화 가이드](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-performance.html)
* [S3 이벤트 알림](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)
