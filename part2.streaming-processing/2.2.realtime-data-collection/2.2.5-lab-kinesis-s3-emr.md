# 2.2.5. ì‹¤ìŠµ: Kinesis â†’ S3 â†’ EMR íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

## ì‹¤ìŠµ ëª©í‘œ
* Kinesis Data Firehoseë¥¼ í†µí•œ S3 ìžë™ ì €ìž¥ ì„¤ì •
* S3 ì´ë²¤íŠ¸ ê¸°ë°˜ EMR ìžë™ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
* ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì˜ ë°°ì¹˜ ì²˜ë¦¬ ë° ë¶„ì„
* ì™„ì „ ìžë™í™”ëœ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìš´ì˜

## ì‚¬ì „ ì¤€ë¹„

### í•„ìš”í•œ ì†ŒìŠ¤ íŒŒì¼
> ðŸ“ **ì‹¤ìŠµ ì†ŒìŠ¤ ì½”ë“œ**: [`2.2.5.src/`](2.2.5.src/) ë””ë ‰í† ë¦¬
> - `streaming_processor.py`: Spark ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
> - `s3_emr_trigger.py`: Lambda S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° í•¨ìˆ˜
> - `test_pipeline.py`: íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
> - `check_results.py`: ì²˜ë¦¬ ê²°ê³¼ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

### í•„ìš”í•œ AWS ì„œë¹„ìŠ¤
* **Kinesis Data Streams**: ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
* **Kinesis Data Firehose**: S3 ìžë™ ì „ì†¡
* **S3**: ë°ì´í„° ë ˆì´í¬ ì €ìž¥ì†Œ
* **EMR**: Spark ë°°ì¹˜ ì²˜ë¦¬
* **Lambda**: S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
* **CloudWatch**: ëª¨ë‹ˆí„°ë§ ë° ì•ŒëžŒ

### IAM ì—­í•  ì¤€ë¹„
```bash
# Firehose ì „ì†¡ ì—­í•  ìƒì„±
aws iam create-role \
    --role-name FirehoseDeliveryRole \
    --assume-role-policy-document '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "firehose.amazonaws.com"},
            "Action": "sts:AssumeRole"
        }]
    }'

# S3 ì“°ê¸° ê¶Œí•œ ì •ì±… ì—°ê²°
aws iam attach-role-policy \
    --role-name FirehoseDeliveryRole \
    --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
```

## Step 1: S3 ë²„í‚· ë° êµ¬ì¡° ì„¤ì •

### ë°ì´í„° ë ˆì´í¬ ë²„í‚· ìƒì„±
```bash
# ê³ ìœ í•œ ë²„í‚· ì´ë¦„ìœ¼ë¡œ ìƒì„±
export BUCKET_NAME=$(cat ~/BUCKET_NAME)
aws s3 mb s3://$BUCKET_NAME --region us-east-1

# ë²„í‚· ì •ì±… ì„¤ì • (ì„ íƒì‚¬í•­)
aws s3api put-bucket-policy \
    --bucket $BUCKET_NAME \
    --policy '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "firehose.amazonaws.com"},
            "Action": ["s3:PutObject", "s3:GetObject", "s3:ListBucket"],
            "Resource": ["arn:aws:s3:::'"$BUCKET_NAME"'/*", "arn:aws:s3:::'"$BUCKET_NAME"'"]
        }]
    }'
```

### í´ë” êµ¬ì¡° ìƒì„±
```bash
# ê¸°ë³¸ í´ë” êµ¬ì¡° ìƒì„±
aws s3 cp /dev/null s3://$BUCKET_NAME/scripts/
aws s3 cp /dev/null s3://$BUCKET_NAME/streaming-data/
aws s3 cp /dev/null s3://$BUCKET_NAME/processed-data/
aws s3 cp /dev/null s3://$BUCKET_NAME/emr-logs/
```

## Step 2: Kinesis Data Firehose ì„¤ì •

### Firehose ì „ì†¡ ìŠ¤íŠ¸ë¦¼ ìƒì„±
```bash
# ì „ì†¡ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
cat > firehose-config.json << 'EOF'
{
    "DeliveryStreamName": "streaming-to-s3-pipeline",
    "DeliveryStreamType": "KinesisStreamAsSource",
    "KinesisStreamSourceConfiguration": {
        "KinesisStreamARN": "arn:aws:kinesis:us-east-1:ACCOUNT_ID:stream/log-streaming-demo",
        "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole"
    },
    "ExtendedS3DestinationConfiguration": {
        "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole",
        "BucketARN": "arn:aws:s3:::BUCKET_NAME",
        "Prefix": "streaming-data/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/hour=!{timestamp:HH}/",
        "ErrorOutputPrefix": "streaming-errors/",
        "BufferingHints": {
            "SizeInMBs": 128,
            "IntervalInSeconds": 300
        },
        "CompressionFormat": "SNAPPY",
        "DataFormatConversionConfiguration": {
            "Enabled": true,
            "OutputFormatConfiguration": {
                "Serializer": {
                    "ParquetSerDe": {}
                }
            },
            "SchemaConfiguration": {
                "DatabaseName": "streaming_db",
                "TableName": "log_events",
                "RoleARN": "arn:aws:iam::ACCOUNT_ID:role/FirehoseDeliveryRole"
            }
        },
        "CloudWatchLoggingOptions": {
            "Enabled": true,
            "LogGroupName": "/aws/kinesisfirehose/streaming-to-s3-pipeline"
        }
    }
}
EOF

# ê³„ì • IDì™€ ë²„í‚· ì´ë¦„ ì¹˜í™˜
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
sed -i "s/ACCOUNT_ID/$ACCOUNT_ID/g" firehose-config.json
sed -i "s/BUCKET_NAME/$(cat ~/BUCKET_NAME)/g" firehose-config.json

# Firehose ìŠ¤íŠ¸ë¦¼ ìƒì„±
aws firehose create-delivery-stream \
    --cli-input-json file://firehose-config.json
```

### Firehose ìƒíƒœ í™•ì¸
```bash
# ìƒì„± ìƒíƒœ ëª¨ë‹ˆí„°ë§
while [ "$(aws firehose describe-delivery-stream --delivery-stream-name streaming-to-s3-pipeline --query 'DeliveryStreamDescription.DeliveryStreamStatus' --output text)" != "ACTIVE" ]; do
    echo "Firehose ìŠ¤íŠ¸ë¦¼ ìƒì„± ì¤‘..."
    sleep 30
done
echo "Firehose ìŠ¤íŠ¸ë¦¼ ì¤€ë¹„ ì™„ë£Œ!"
```

## Step 3: EMR í´ëŸ¬ìŠ¤í„° ìƒì„±

### í´ëŸ¬ìŠ¤í„° ì„¤ì • íŒŒì¼ ìƒì„±
```bash
cat > emr-cluster-config.json << 'EOF'
{
    "Name": "streaming-processing-cluster",
    "ReleaseLabel": "emr-6.15.0",
    "Applications": [
        {"Name": "Spark"},
        {"Name": "Hadoop"},
        {"Name": "Hive"}
    ],
    "Instances": {
        "InstanceGroups": [
            {
                "Name": "Master",
                "Market": "ON_DEMAND",
                "InstanceRole": "MASTER",
                "InstanceType": "m5.xlarge",
                "InstanceCount": 1
            },
            {
                "Name": "Core",
                "Market": "SPOT",
                "BidPrice": "0.20",
                "InstanceRole": "CORE",
                "InstanceType": "m5.large",
                "InstanceCount": 2
            }
        ],
        "KeepJobFlowAliveWhenNoSteps": true,
        "TerminationProtected": false
    },
    "ServiceRole": "EMR_DefaultRole",
    "JobFlowRole": "EMR_EC2_DefaultRole",
    "LogUri": "s3://BUCKET_NAME/emr-logs/",
    "Configurations": [
        {
            "Classification": "spark-defaults",
            "Properties": {
                "spark.sql.adaptive.enabled": "true",
                "spark.sql.adaptive.coalescePartitions.enabled": "true",
                "spark.hadoop.fs.s3a.multipart.size": "134217728",
                "spark.sql.parquet.compression.codec": "snappy",
                "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
            }
        }
    ],
    "AutoTerminationPolicy": {
        "IdleTimeout": 14400
    },
    "Tags": [
        {"Key": "Project", "Value": "StreamingPipeline"},
        {"Key": "Environment", "Value": "Demo"}
    ]
}
EOF

# ë²„í‚· ì´ë¦„ ì¹˜í™˜
sed -i "s/BUCKET_NAME/$BUCKET_NAME/g" emr-cluster-config.json

# EMR í´ëŸ¬ìŠ¤í„° ìƒì„±
CLUSTER_ID=$(aws emr create-cluster \
    --cli-input-json file://emr-cluster-config.json \
    --query 'JobFlowId' --output text)

echo "EMR í´ëŸ¬ìŠ¤í„° ìƒì„±ë¨: $CLUSTER_ID"
```

### í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ëŒ€ê¸°
```bash
# í´ëŸ¬ìŠ¤í„° WAITING ìƒíƒœê¹Œì§€ ëŒ€ê¸°
echo "EMR í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ëŒ€ê¸° ì¤‘..."
while [ "$(aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --output text)" != "WAITING" ]; do
    STATE=$(aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --output text)
    echo "í˜„ìž¬ ìƒíƒœ: $STATE"
    if [ "$STATE" = "TERMINATED" ] || [ "$STATE" = "TERMINATED_WITH_ERRORS" ]; then
        echo "í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹¤íŒ¨!"
        exit 1
    fi
    sleep 60
done
echo "EMR í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ì™„ë£Œ!"
```

## Step 4: Spark ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì—…ë¡œë“œ

### ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ë° ì—…ë¡œë“œ
```bash
# 2.2.5.src ë””ë ‰í† ë¦¬ì—ì„œ Spark ìŠ¤í¬ë¦½íŠ¸ë¥¼ S3ì— ì—…ë¡œë“œ
aws s3 cp 2.2.5.src/streaming_processor.py s3://$BUCKET_NAME/scripts/

# ì‹¤í–‰ ê¶Œí•œ í™•ì¸
aws s3api head-object --bucket $BUCKET_NAME --key scripts/streaming_processor.py
```

## Step 5: Lambda íŠ¸ë¦¬ê±° í•¨ìˆ˜ ìƒì„±

### Lambda í•¨ìˆ˜ íŒ¨í‚¤ì§• ë° ë°°í¬
```bash
# 2.2.5.src ë””ë ‰í† ë¦¬ì—ì„œ Lambda í•¨ìˆ˜ ì½”ë“œë¥¼ íŒ¨í‚¤ì§•
cd 2.2.5.src/
zip s3-emr-trigger.zip s3_emr_trigger.py
cd ..

# Lambda ì‹¤í–‰ ì—­í•  ìƒì„±
aws iam create-role \
    --role-name lambda-s3-emr-trigger-role \
    --assume-role-policy-document '{
        "Version": "2012-10-17",
        "Statement": [{
            "Effect": "Allow",
            "Principal": {"Service": "lambda.amazonaws.com"},
            "Action": "sts:AssumeRole"
        }]
    }' || true

# í•„ìš”í•œ ì •ì±… ì—°ê²°
aws iam attach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

aws iam attach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/ElasticMapReduceFullAccess

# Lambda í•¨ìˆ˜ ìƒì„±
LAMBDA_ROLE_ARN="arn:aws:iam::$ACCOUNT_ID:role/lambda-s3-emr-trigger-role"

aws lambda create-function \
    --function-name s3-emr-trigger \
    --runtime python3.9 \
    --role $LAMBDA_ROLE_ARN \
    --handler s3_emr_trigger.lambda_handler \
    --zip-file fileb://2.2.5.src/s3-emr-trigger.zip \
    --timeout 300 \
    --environment Variables="{EMR_CLUSTER_ID=$CLUSTER_ID}" \
    --tags Project=StreamingPipeline,Environment=Demo
```

### S3 ì´ë²¤íŠ¸ ì•Œë¦¼ ì„¤ì •
```bash
# S3 ì´ë²¤íŠ¸ ì•Œë¦¼ ì„¤ì •
LAMBDA_ARN="arn:aws:lambda:us-east-1:$ACCOUNT_ID:function:s3-emr-trigger"

# Lambda í•¨ìˆ˜ì— S3 í˜¸ì¶œ ê¶Œí•œ ë¶€ì—¬
aws lambda add-permission \
    --function-name s3-emr-trigger \
    --principal s3.amazonaws.com \
    --action lambda:InvokeFunction \
    --statement-id s3-trigger-permission \
    --source-arn arn:aws:s3:::$BUCKET_NAME

# S3 ì´ë²¤íŠ¸ ì•Œë¦¼ ì„¤ì •
aws s3api put-bucket-notification-configuration \
    --bucket $BUCKET_NAME \
    --notification-configuration '{
        "LambdaConfigurations": [{
            "Id": "emr-trigger-notification",
            "LambdaFunctionArn": "'$LAMBDA_ARN'",
            "Events": ["s3:ObjectCreated:*"],
            "Filter": {
                "Key": {
                    "FilterRules": [{
                        "Name": "prefix",
                        "Value": "streaming-data/"
                    }]
                }
            }
        }]
    }'
```

## Step 6: íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì†¡
```bash
# í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python 2.2.5.src/test_pipeline.py
```

### íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
```bash
# Firehose ìŠ¤íŠ¸ë¦¼ ìƒíƒœ í™•ì¸
aws firehose describe-delivery-stream \
    --delivery-stream-name streaming-to-s3-pipeline \
    --query 'DeliveryStreamDescription.DeliveryStreamStatus'

# S3ì— ë°ì´í„° ë„ì°© í™•ì¸ (5-10ë¶„ í›„)
echo "S3 ë°ì´í„° í™•ì¸ ì¤‘..."
aws s3 ls s3://$BUCKET_NAME/streaming-data/ --recursive

# EMR Step ìƒíƒœ í™•ì¸
echo "EMR ìž‘ì—… ìƒíƒœ í™•ì¸..."
aws emr list-steps --cluster-id $CLUSTER_ID \
    --query 'Steps[*].{Name:Name,State:Status.State,CreationDateTime:Status.Timeline.CreationDateTime}'
```

## Step 7: ê²°ê³¼ ë°ì´í„° í™•ì¸

### ì²˜ë¦¬ ê²°ê³¼ ì¡°íšŒ
```bash
# ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸
echo "ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸..."
aws s3 ls s3://$BUCKET_NAME/processed-data/ --recursive

# ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° í™•ì¸
mkdir -p ./pipeline-results
aws s3 sync s3://$BUCKET_NAME/processed-data/ ./pipeline-results/

# Parquet íŒŒì¼ ë‚´ìš© í™•ì¸
pip install pandas pyarrow
python 2.2.5.src/check_results.py --bucket-name $BUCKET_NAME --download
```

## Step 8: ëª¨ë‹ˆí„°ë§ ë° ì•ŒëžŒ ì„¤ì •

### CloudWatch ëŒ€ì‹œë³´ë“œ ìƒì„±
```bash
cat > dashboard-config.json << 'EOF'
{
    "widgets": [
        {
            "type": "metric",
            "properties": {
                "metrics": [
                    ["AWS/Kinesis", "IncomingRecords", "StreamName", "log-streaming-demo"],
                    ["AWS/KinesisFirehose", "DeliveryToS3.Records", "DeliveryStreamName", "streaming-to-s3-pipeline"]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "us-east-1",
                "title": "ë°ì´í„° ì²˜ë¦¬ëŸ‰"
            }
        },
        {
            "type": "metric", 
            "properties": {
                "metrics": [
                    ["AWS/ElasticMapReduce", "StepsRunning", "JobFlowId", "CLUSTER_ID"],
                    ["AWS/ElasticMapReduce", "StepsCompleted", "JobFlowId", "CLUSTER_ID"],
                    ["AWS/ElasticMapReduce", "StepsFailed", "JobFlowId", "CLUSTER_ID"]
                ],
                "period": 300,
                "stat": "Average",
                "region": "us-east-1", 
                "title": "EMR ìž‘ì—… ìƒíƒœ"
            }
        }
    ]
}
EOF

# í´ëŸ¬ìŠ¤í„° ID ì¹˜í™˜
sed -i "s/CLUSTER_ID/$CLUSTER_ID/g" dashboard-config.json

# ëŒ€ì‹œë³´ë“œ ìƒì„±
aws cloudwatch put-dashboard \
    --dashboard-name "StreamingPipelineDashboard" \
    --dashboard-body file://dashboard-config.json
```

### ì•ŒëžŒ ì„¤ì •
```bash
# EMR Step ì‹¤íŒ¨ ì•ŒëžŒ
aws cloudwatch put-metric-alarm \
    --alarm-name "EMR-Steps-Failed" \
    --alarm-description "EMR steps failed alarm" \
    --metric-name StepsFailed \
    --namespace AWS/ElasticMapReduce \
    --statistic Sum \
    --period 300 \
    --threshold 0 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 1 \
    --dimensions Name=JobFlowId,Value=$CLUSTER_ID

# Firehose ì „ì†¡ ì˜¤ë¥˜ ì•ŒëžŒ
aws cloudwatch put-metric-alarm \
    --alarm-name "Firehose-Delivery-Errors" \
    --alarm-description "Firehose delivery errors" \
    --metric-name DeliveryToS3.DataFreshness \
    --namespace AWS/KinesisFirehose \
    --statistic Maximum \
    --period 300 \
    --threshold 3600 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 2 \
    --dimensions Name=DeliveryStreamName,Value=streaming-to-s3-pipeline
```

## Step 9: ì„±ëŠ¥ ìµœì í™” ë° íŠœë‹

### Firehose ë°°ì¹˜ ì„¤ì • ìµœì í™”
```bash
# ë” ìžì£¼ ì „ì†¡í•˜ë„ë¡ ì„¤ì • ìˆ˜ì •
aws firehose update-destination \
    --delivery-stream-name streaming-to-s3-pipeline \
    --version-id 1 \
    --destination-id destinationId-000000000001 \
    --extended-s3-destination-update '{
        "BufferingHints": {
            "SizeInMBs": 64,
            "IntervalInSeconds": 180
        }
    }'
```

### EMR í´ëŸ¬ìŠ¤í„° ìžë™ ìŠ¤ì¼€ì¼ë§
```bash
# ìžë™ ìŠ¤ì¼€ì¼ë§ ì •ì±… ì¶”ê°€
aws emr put-auto-scaling-policy \
    --cluster-id $CLUSTER_ID \
    --instance-group-id ig-XXXXXXXXXX \
    --auto-scaling-policy '{
        "Constraints": {
            "MinCapacity": 2,
            "MaxCapacity": 10
        },
        "Rules": [{
            "Name": "ScaleOutMemoryPercentage",
            "Description": "Scale out if YARNMemoryAvailablePercentage is less than 15",
            "Action": {
                "Market": "ON_DEMAND",
                "SimpleScalingPolicyConfiguration": {
                    "AdjustmentType": "CHANGE_IN_CAPACITY",
                    "ScalingAdjustment": 1,
                    "CoolDown": 300
                }
            },
            "Trigger": {
                "CloudWatchAlarmDefinition": {
                    "ComparisonOperator": "LESS_THAN_OR_EQUAL",
                    "EvaluationPeriods": 1,
                    "MetricName": "YARNMemoryAvailablePercentage",
                    "Namespace": "AWS/ElasticMapReduce",
                    "Period": 300,
                    "Statistic": "AVERAGE",
                    "Threshold": 15.0,
                    "Unit": "PERCENT"
                }
            }
        }]
    }'
```

## Step 10: ë¬¸ì œ í•´ê²° ë° ë””ë²„ê¹…

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

#### Firehose ì „ì†¡ ì‹¤íŒ¨
```bash
# Firehose ë¡œê·¸ í™•ì¸
aws logs describe-log-groups \
    --log-group-name-prefix "/aws/kinesisfirehose/"

aws logs get-log-events \
    --log-group-name "/aws/kinesisfirehose/streaming-to-s3-pipeline" \
    --log-stream-name "S3Delivery"
```

#### Lambda í•¨ìˆ˜ ì˜¤ë¥˜
```bash
# Lambda í•¨ìˆ˜ ë¡œê·¸ í™•ì¸
aws logs describe-log-groups \
    --log-group-name-prefix "/aws/lambda/s3-emr-trigger"

aws logs get-log-events \
    --log-group-name "/aws/lambda/s3-emr-trigger" \
    --log-stream-name "ìµœì‹ _ë¡œê·¸_ìŠ¤íŠ¸ë¦¼_ì´ë¦„"
```

#### EMR Step ì‹¤íŒ¨
```bash
# EMR Step ìƒì„¸ ì •ë³´ í™•ì¸
STEP_ID=$(aws emr list-steps --cluster-id $CLUSTER_ID --query 'Steps[0].Id' --output text)

aws emr describe-step \
    --cluster-id $CLUSTER_ID \
    --step-id $STEP_ID

# EMR ë¡œê·¸ í™•ì¸
aws s3 ls s3://$BUCKET_NAME/emr-logs/ --recursive
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¿¼ë¦¬
```bash
# Kinesis ì²˜ë¦¬ëŸ‰ í™•ì¸
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=log-streaming-demo \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Sum

# EMR ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElasticMapReduce \
    --metric-name YARNMemoryAvailablePercentage \
    --dimensions Name=JobFlowId,Value=$CLUSTER_ID \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average
```

## ì‹¤ìŠµ ê²°ê³¼ í™•ì¸

### ì„±ê³µ ê¸°ì¤€
- [ ] Kinesis â†’ Firehose â†’ S3 ë°ì´í„° íë¦„ ì •ìƒ ë™ìž‘
- [ ] S3 íŒŒí‹°ì…˜ êµ¬ì¡° ì˜¬ë°”ë¥´ê²Œ ìƒì„± (year/month/day/hour)
- [ ] Lambda íŠ¸ë¦¬ê±°ë¥¼ í†µí•œ EMR ìžë™ ì‹¤í–‰
- [ ] Spark ìž‘ì—… ì„±ê³µì  ì™„ë£Œ ë° ê²°ê³¼ ë°ì´í„° ìƒì„±
- [ ] CloudWatch ëª¨ë‹ˆí„°ë§ ë° ì•ŒëžŒ ì •ìƒ ë™ìž‘

### ê¸°ëŒ€ ê²°ê³¼
* **ë°ì´í„° ì§€ì—°ì‹œê°„**: 5-10ë¶„ (Firehose ë²„í¼ë§ + EMR ì²˜ë¦¬)
* **ì²˜ë¦¬ ì„±ê³µë¥ **: 95% ì´ìƒ
* **ìžë™í™” ìˆ˜ì¤€**: ì™„ì „ ìžë™ (ìˆ˜ë™ ê°œìž… ë¶ˆí•„ìš”)
* **ë¹„ìš© íš¨ìœ¨ì„±**: ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ í™œìš©ìœ¼ë¡œ 30-50% ì ˆì•½

## ì •ë¦¬ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬

### ì‹¤ìŠµ ì™„ë£Œ í›„ ì •ë¦¬
```bash
# EMR í´ëŸ¬ìŠ¤í„° ì¢…ë£Œ
aws emr terminate-clusters --cluster-ids $CLUSTER_ID

# Lambda í•¨ìˆ˜ ì‚­ì œ
aws lambda delete-function --function-name s3-emr-trigger

# Firehose ìŠ¤íŠ¸ë¦¼ ì‚­ì œ
aws firehose delete-delivery-stream \
    --delivery-stream-name streaming-to-s3-pipeline

# S3 ë²„í‚· ë‚´ìš© ì‚­ì œ í›„ ë²„í‚· ì‚­ì œ
aws s3 rm s3://$BUCKET_NAME --recursive
aws s3 rb s3://$BUCKET_NAME

# CloudWatch ëŒ€ì‹œë³´ë“œ ì‚­ì œ
aws cloudwatch delete-dashboards \
    --dashboard-names StreamingPipelineDashboard

# CloudWatch ì•ŒëžŒ ì‚­ì œ
aws cloudwatch delete-alarms \
    --alarm-names EMR-Steps-Failed Firehose-Delivery-Errors

# IAM ì—­í•  ì •ë¦¬
aws iam detach-role-policy \
    --role-name FirehoseDeliveryRole \
    --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
aws iam delete-role --role-name FirehoseDeliveryRole

aws iam detach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
aws iam detach-role-policy \
    --role-name lambda-s3-emr-trigger-role \
    --policy-arn arn:aws:iam::aws:policy/ElasticMapReduceFullAccess
aws iam delete-role --role-name lambda-s3-emr-trigger-role
```

## ë‹¤ìŒ ë‹¨ê³„
* **2.3.1**: Kinesis Data Firehose ë³€í™˜ ê¸°ëŠ¥ ì‹¬í™”
* **2.3.4**: ì‹¤ì‹œê°„ ETL íŒŒì´í”„ë¼ì¸ êµ¬í˜„
* **3.2**: CloudWatch ê¸°ë°˜ í†µí•© ëª¨ë‹ˆí„°ë§ êµ¬ì¶•

## ì°¸ê³  ìžë£Œ
* [Kinesis Data Firehose ê°œë°œìž ê°€ì´ë“œ](https://docs.aws.amazon.com/kinesis/latest/dev/)
* [EMR Spark ìµœì í™” ê°€ì´ë“œ](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-performance.html)
* [S3 ì´ë²¤íŠ¸ ì•Œë¦¼](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)
