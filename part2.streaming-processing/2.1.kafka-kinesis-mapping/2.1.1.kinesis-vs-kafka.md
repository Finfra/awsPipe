# 1.1 Kinesis vs Kafka 비교

## 스트리밍 플랫폼 비교

### Apache Kafka vs Amazon Kinesis
| 구분          | Apache Kafka       | Amazon Kinesis                    |
| ------------- | ------------------ | --------------------------------- |
| **아키텍처**  | 분산 로그 시스템   | 완전 관리형 서비스                |
| **확장성**    | 수동 파티션 관리   | 자동/수동 샤드 관리               |
| **내구성**    | 복제 설정 기반     | 3개 AZ 자동 복제                  |
| **운영 관리** | 클러스터 직접 관리 | AWS 완전 관리                     |
| **처리량**    | 파티션당 무제한    | 샤드당 1MB/초 또는 1000 레코드/초 |
| **보존 기간** | 설정 가능 (무제한) | 최대 365일                        |
| **비용 모델** | 인프라 + 운영 비용 | 샤드 시간 + 데이터 전송량         |

## Kinesis 서비스 구성

### Kinesis Data Streams
* **목적**: 실시간 데이터 스트리밍 수집
* **특징**: 
    - 낮은 지연시간 (1초 미만)
    - 사용자 정의 애플리케이션으로 처리
    - 순서 보장 (파티션 키 기준)
* **사용 사례**: 실시간 분석, 로그 처리, IoT 데이터

### 실습용 스크립트 제공
소스 파일: `2.1.1.src/create-kinesis-streams.sh`

주요 기능:
* Kinesis 스트림 생성 및 설정 자동화
* 스트림 상태 모니터링 및 테스트
* 태그 설정 및 보존 기간 구성
* CloudWatch 메트릭 확인

```bash
# 기본 설정으로 스트림 생성
bash 2.1.1.src/create-kinesis-streams.sh

# 커스텀 설정으로 생성
bash 2.1.1.src/create-kinesis-streams.sh my-stream 4 PROVISIONED 48
```

```python
# Python SDK 예시
import boto3

def create_kinesis_stream():
    kinesis = boto3.client('kinesis')
    
    response = kinesis.create_stream(
        StreamName='realtime-events',
        ShardCount=2,
        StreamModeDetails={
            'StreamMode': 'PROVISIONED'  # or 'ON_DEMAND'
        }
    )
    
    return response
```

### Kinesis Data Firehose
* **목적**: 데이터를 목적지로 안정적 전송
* **특징**:
    - 자동 스케일링
    - 배치 처리 (버퍼 크기/시간 기준)
    - 변환 및 압축 지원
* **사용 사례**: S3 저장, Redshift 로딩, ElasticSearch 인덱싱

```python
# Kinesis Data Firehose 생성
def create_firehose_delivery_stream():
    firehose = boto3.client('firehose')
    
    response = firehose.create_delivery_stream(
        DeliveryStreamName='logs-to-s3',
        DeliveryStreamType='DirectPut',
        S3DestinationConfiguration={
            'RoleARN': 'arn:aws:iam::account:role/firehose-role',
            'BucketARN': 'arn:aws:s3:::my-data-lake',
            'Prefix': 'logs/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/',
            'BufferingHints': {
                'SizeInMBs': 5,
                'IntervalInSeconds': 300
            },
            'CompressionFormat': 'GZIP'
        }
    )
    
    return response
```

### Kinesis Data Analytics
* **목적**: 실시간 스트림 분석
* **특징**:
    - SQL 기반 분석
    - Apache Flink 지원
    - 자동 스케일링
* **사용 사례**: 실시간 대시보드, 이상 탐지, 윈도우 집계

## 마이그레이션 전략

### Kafka → Kinesis 매핑 가이드

#### 1. 개념 매핑
| Kafka 개념 | Kinesis 개념 | 설명 |
|------------|--------------|------|
| Topic | Stream | 데이터 스트림 단위 |
| Partition | Shard | 처리 단위 |
| Producer | Producer/PutRecord | 데이터 생산자 |
| Consumer | Consumer/GetRecords | 데이터 소비자 |
| Consumer Group | Application | 소비자 그룹 |
| Offset | Sequence Number | 레코드 위치 |

#### 2. 처리량 계산
```python
def calculate_kinesis_shards(kafka_throughput_mb_per_sec):
    """Kafka 처리량 기준 Kinesis 샤드 수 계산"""
    
    # Kinesis 샤드 제한: 1MB/초 또는 1000 레코드/초
    kinesis_shard_limit_mb = 1
    
    required_shards = max(
        int(kafka_throughput_mb_per_sec / kinesis_shard_limit_mb) + 1,
        1
    )
    
    return {
        'required_shards': required_shards,
        'throughput_per_shard': kafka_throughput_mb_per_sec / required_shards,
        'estimated_cost_per_hour': required_shards * 0.015  # $0.015 per shard hour
    }

# 사용 예시
kafka_throughput = 5  # 5MB/초
shard_calculation = calculate_kinesis_shards(kafka_throughput)
print(f"필요한 샤드 수: {shard_calculation['required_shards']}")
print(f"시간당 예상 비용: ${shard_calculation['estimated_cost_per_hour']:.2f}")
```

#### 3. 코드 마이그레이션

**Kafka Producer → Kinesis Producer**
```python
# Before: Kafka Producer
from kafka import KafkaProducer
import json

kafka_producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

kafka_producer.send('events', {'user_id': 123, 'action': 'click'})

# After: Kinesis Producer
import boto3
import json

kinesis = boto3.client('kinesis')

kinesis.put_record(
    StreamName='events',
    Data=json.dumps({'user_id': 123, 'action': 'click'}),
    PartitionKey='user_123'
)
```

**Kafka Consumer → Kinesis Consumer**
```python
# Before: Kafka Consumer
from kafka import KafkaConsumer

consumer = KafkaConsumer(
    'events',
    bootstrap_servers=['localhost:9092'],
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

for message in consumer:
    process_event(message.value)

# After: Kinesis Consumer (Polling)
def consume_kinesis_stream():
    kinesis = boto3.client('kinesis')
    
    # 샤드 목록 조회
    stream_desc = kinesis.describe_stream(StreamName='events')
    shards = stream_desc['StreamDescription']['Shards']
    
    for shard in shards:
        shard_id = shard['ShardId']
        
        # 샤드 이터레이터 생성
        iterator_response = kinesis.get_shard_iterator(
            StreamName='events',
            ShardId=shard_id,
            ShardIteratorType='LATEST'
        )
        
        shard_iterator = iterator_response['ShardIterator']
        
        while shard_iterator:
            # 레코드 조회
            response = kinesis.get_records(ShardIterator=shard_iterator)
            
            for record in response['Records']:
                data = json.loads(record['Data'])
                process_event(data)
            
            shard_iterator = response.get('NextShardIterator')
            time.sleep(1)  # 1초 대기
```

## 성능 및 비용 비교

### 처리량 기준 비교
```python
def compare_streaming_costs():
    """스트리밍 플랫폼 비용 비교"""
    
    # 가정: 10MB/초 처리량, 24시간 운영
    throughput_mb_per_sec = 10
    hours_per_day = 24
    days_per_month = 30
    
    # Kafka (EC2 기반) 비용
    kafka_instances = 3  # r5.large 3대
    kafka_cost_per_hour = 0.126 * kafka_instances  # r5.large 시간당 비용
    kafka_monthly_cost = kafka_cost_per_hour * hours_per_day * days_per_month
    
    # Kinesis 비용
    required_shards = max(int(throughput_mb_per_sec / 1) + 1, 1)
    kinesis_shard_cost = required_shards * 0.015 * hours_per_day * days_per_month
    kinesis_data_cost = throughput_mb_per_sec * 3600 * hours_per_day * days_per_month * 0.000014  # PUT 요청당 $0.000014
    kinesis_monthly_cost = kinesis_shard_cost + kinesis_data_cost
    
    return {
        'kafka': {
            'monthly_cost': kafka_monthly_cost,
            'components': {'infrastructure': kafka_monthly_cost}
        },
        'kinesis': {
            'monthly_cost': kinesis_monthly_cost,
            'components': {
                'shard_hours': kinesis_shard_cost,
                'put_requests': kinesis_data_cost
            }
        },
        'savings': kafka_monthly_cost - kinesis_monthly_cost,
        'savings_percentage': ((kafka_monthly_cost - kinesis_monthly_cost) / kafka_monthly_cost) * 100
    }

cost_comparison = compare_streaming_costs()
print(f"Kafka 월 비용: ${cost_comparison['kafka']['monthly_cost']:.2f}")
print(f"Kinesis 월 비용: ${cost_comparison['kinesis']['monthly_cost']:.2f}")
print(f"절약 금액: ${cost_comparison['savings']:.2f} ({cost_comparison['savings_percentage']:.1f}%)")
```

## 마이그레이션 체크리스트

### 사전 준비사항
- [ ] 현재 Kafka 토픽별 처리량 측정
- [ ] 메시지 크기 및 형식 분석
- [ ] 소비자 애플리케이션 목록 작성
- [ ] 보존 기간 요구사항 확인
- [ ] 순서 보장 요구사항 분석

### 마이그레이션 단계
- [ ] Kinesis 스트림 생성 및 테스트
- [ ] Producer 애플리케이션 마이그레이션
- [ ] Consumer 애플리케이션 마이그레이션
- [ ] 병렬 운영 및 검증
- [ ] 트래픽 전환
- [ ] Kafka 인프라 정리

### 검증 항목
- [ ] 메시지 손실 없음 확인
- [ ] 처리 지연시간 측정
- [ ] 에러율 모니터링
- [ ] 비용 추적
- [ ] 성능 메트릭 비교

## 권장사항

### Kinesis 선택 기준
* **관리 오버헤드 최소화**: 운영 팀이 작은 경우
* **AWS 생태계 통합**: 다른 AWS 서비스와 연동이 많은 경우
* **예측 가능한 처리량**: 급격한 스케일링이 필요하지 않은 경우
* **높은 가용성**: 99.9% 이상의 SLA가 필요한 경우

### Kafka 유지 기준
* **높은 처리량**: 매우 높은 처리량이 필요한 경우
* **커스텀 처리**: 복잡한 스트림 처리 로직이 필요한 경우
* **멀티 클라우드**: 여러 클라우드 환경에서 운영하는 경우
* **기존 투자**: Kafka 전문 인력과 인프라가 이미 있는 경우

## 실제 마이그레이션 사례

### 사례 1: 로그 스트리밍 시스템
**기존**: Kafka 클러스터 (5개 브로커, 20개 파티션)
**마이그레이션 후**: Kinesis Data Streams (10개 샤드)
**결과**: 
* 운영 비용 40% 절감
* 가용성 99.9% → 99.99% 향상
* 관리 시간 80% 단축

### 사례 2: 실시간 분석 파이프라인
**기존**: Kafka + Kafka Streams
**마이그레이션 후**: Kinesis + Kinesis Analytics
**결과**:
* 개발 시간 60% 단축
* 장애 복구 시간 90% 단축
* 스케일링 자동화 100%
