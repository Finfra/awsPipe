# 2.1.3 실습: Kinesis Data Streams 생성

## 실습 목표
* AWS CLI와 Terraform을 사용하여 Kinesis Data Streams 생성
* 스트림 설정 및 구성 최적화
* 기본적인 데이터 전송 및 수신 테스트
* 모니터링 및 관리 방법 습득

## 사전 요구사항
* AWS CLI 설치 및 구성
* Terraform 설치 (>= 1.0)
* 적절한 IAM 권한 보유
* jq 설치 (JSON 파싱용)

## 실습 환경 설정

### 1. 필수 도구 확인
```bash
# AWS CLI 버전 확인
aws --version

# Terraform 버전 확인
terraform --version

# jq 설치 확인
jq --version

# AWS 자격 증명 확인
aws sts get-caller-identity
```

### 2. 실습 디렉토리 설정
```bash
mkdir kinesis-lab
cd kinesis-lab
```

## 방법 1: AWS CLI로 Kinesis 스트림 생성

### 1. 기본 스트림 생성
```bash
# 스트림 생성 (2개 샤드)
aws kinesis create-stream \
    --stream-name lab-data-stream \
    --shard-count 2

# 스트림 상태 확인
aws kinesis describe-stream \
    --stream-name lab-data-stream
```

### 2. 스트림 활성화 대기
```bash
# 스트림이 ACTIVE 상태가 될 때까지 대기
while true; do
    STATUS=$(aws kinesis describe-stream \
        --stream-name lab-data-stream \
        --query 'StreamDescription.StreamStatus' \
        --output text)
    
    echo "스트림 상태: $STATUS"
    
    if [ "$STATUS" = "ACTIVE" ]; then
        echo "✅ 스트림 활성화 완료"
        break
    fi
    
    sleep 10
done
```

### 3. 스트림 설정 조정
```bash
# 데이터 보존 기간 설정 (24시간 → 168시간)
aws kinesis increase-stream-retention-period \
    --stream-name lab-data-stream \
    --retention-period-hours 168

# 샤드 레벨 메트릭 활성화
aws kinesis enable-enhanced-monitoring \
    --stream-name lab-data-stream \
    --shard-level-metrics IncomingRecords,OutgoingRecords
```

## 방법 2: Terraform으로 인프라 구성

### 1. Terraform 설정 파일 작성

**main.tf**
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.region
}

# Kinesis Data Stream
resource "aws_kinesis_stream" "lab_stream" {
  name             = var.stream_name
  shard_count      = var.shard_count
  retention_period = var.retention_hours

  shard_level_metrics = [
    "IncomingRecords",
    "OutgoingRecords",
    "WriteProvisionedThroughputExceeded",
    "ReadProvisionedThroughputExceeded"
  ]

  tags = {
    Environment = "lab"
    Project     = "kinesis-hands-on"
  }
}

# CloudWatch 로그 그룹
resource "aws_cloudwatch_log_group" "kinesis_logs" {
  name              = "/aws/kinesis/${var.stream_name}"
  retention_in_days = 7
}
```

**variables.tf**
```hcl
variable "region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "stream_name" {
  description = "Kinesis stream name"
  type        = string
  default     = "lab-data-stream"
}

variable "shard_count" {
  description = "Number of shards"
  type        = number
  default     = 2
}

variable "retention_hours" {
  description = "Data retention period in hours"
  type        = number
  default     = 168
}
```

**outputs.tf**
```hcl
output "stream_name" {
  description = "Name of the Kinesis stream"
  value       = aws_kinesis_stream.lab_stream.name
}

output "stream_arn" {
  description = "ARN of the Kinesis stream"
  value       = aws_kinesis_stream.lab_stream.arn
}

output "shard_count" {
  description = "Number of shards"
  value       = aws_kinesis_stream.lab_stream.shard_count
}
```

### 2. Terraform 실행
```bash
# 초기화
terraform init

# 실행 계획 확인
terraform plan

# 인프라 생성
terraform apply
```

## 실습 3: 데이터 전송 및 수신 테스트

### 1. 테스트 데이터 전송 (Python)

**producer.py**
```python
#!/usr/bin/env python3
import boto3
import json
import time
from datetime import datetime

def send_test_data():
    kinesis = boto3.client('kinesis')
    stream_name = 'lab-data-stream'
    
    for i in range(10):
        data = {
            'timestamp': datetime.utcnow().isoformat(),
            'user_id': 1000 + i,
            'event_type': 'test_event',
            'value': 100 + i * 10
        }
        
        response = kinesis.put_record(
            StreamName=stream_name,
            Data=json.dumps(data),
            PartitionKey=f'user_{1000 + i}'
        )
        
        print(f"전송 완료: {response['SequenceNumber']}")
        time.sleep(1)

if __name__ == "__main__":
    send_test_data()
```

### 2. 데이터 수신 테스트 (Python)

**consumer.py**
```python
#!/usr/bin/env python3
import boto3
import json
import time

def consume_test_data():
    kinesis = boto3.client('kinesis')
    stream_name = 'lab-data-stream'
    
    # 스트림 정보 조회
    response = kinesis.describe_stream(StreamName=stream_name)
    shards = response['StreamDescription']['Shards']
    
    for shard in shards:
        shard_id = shard['ShardId']
        print(f"처리 중인 샤드: {shard_id}")
        
        # 샤드 이터레이터 생성
        iterator_response = kinesis.get_shard_iterator(
            StreamName=stream_name,
            ShardId=shard_id,
            ShardIteratorType='TRIM_HORIZON'
        )
        
        shard_iterator = iterator_response['ShardIterator']
        
        # 레코드 읽기
        records_response = kinesis.get_records(
            ShardIterator=shard_iterator
        )
        
        records = records_response['Records']
        print(f"읽은 레코드 수: {len(records)}")
        
        for record in records:
            data = json.loads(record['Data'])
            print(f"데이터: {data}")

if __name__ == "__main__":
    consume_test_data()
```

### 3. 테스트 실행
```bash
# 의존성 설치
pip install boto3

# 데이터 전송
python producer.py

# 데이터 수신 (별도 터미널)
python consumer.py
```

## 실습 4: 모니터링 및 관리

### 1. CloudWatch 메트릭 확인
```bash
# 스트림 메트릭 조회
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=lab-data-stream \
    --start-time 2024-05-26T09:00:00Z \
    --end-time 2024-05-26T10:00:00Z \
    --period 300 \
    --statistics Sum
```

### 2. 스트림 관리 명령어
```bash
# 스트림 상세 정보
aws kinesis describe-stream \
    --stream-name lab-data-stream \
    --query 'StreamDescription.{
        Name:StreamName,
        Status:StreamStatus,
        Shards:Shards[].ShardId,
        RetentionPeriod:RetentionPeriodHours
    }'

# 샤드 목록 조회
aws kinesis list-shards \
    --stream-name lab-data-stream

# 스트림 태그 확인
aws kinesis list-tags-for-stream \
    --stream-name lab-data-stream
```

### 3. 스케일링 테스트
```bash
# 샤드 수 증가 (2 → 4)
aws kinesis update-shard-count \
    --stream-name lab-data-stream \
    --target-shard-count 4 \
    --scaling-type UNIFORM_SCALING

# 스케일링 상태 확인
aws kinesis describe-stream \
    --stream-name lab-data-stream \
    --query 'StreamDescription.StreamStatus'
```

## 실습 5: 고급 기능 테스트

### 1. 배치 데이터 전송
**batch_producer.py**
```python
#!/usr/bin/env python3
import boto3
import json
from datetime import datetime

def send_batch_data():
    kinesis = boto3.client('kinesis')
    stream_name = 'lab-data-stream'
    
    # 배치 레코드 준비 (최대 500개)
    records = []
    for i in range(100):
        record = {
            'Data': json.dumps({
                'timestamp': datetime.utcnow().isoformat(),
                'batch_id': 'batch_001',
                'record_id': i,
                'value': i * 5
            }),
            'PartitionKey': f'batch_key_{i % 10}'
        }
        records.append(record)
    
    # 배치 전송
    response = kinesis.put_records(
        Records=records,
        StreamName=stream_name
    )
    
    print(f"전송 완료: {len(records)}개 레코드")
    print(f"실패 수: {response['FailedRecordCount']}")
    
    # 실패한 레코드 처리
    if response['FailedRecordCount'] > 0:
        failed_records = []
        for i, record_result in enumerate(response['Records']):
            if 'ErrorCode' in record_result:
                failed_records.append(records[i])
        
        print(f"재시도 필요한 레코드: {len(failed_records)}개")

if __name__ == "__main__":
    send_batch_data()
```

### 2. 실시간 데이터 시뮬레이션
**realtime_simulator.py**
```python
#!/usr/bin/env python3
import boto3
import json
import time
import random
from datetime import datetime
import threading

class KinesisSimulator:
    def __init__(self, stream_name):
        self.kinesis = boto3.client('kinesis')
        self.stream_name = stream_name
        self.running = False
        
    def start_simulation(self, duration_seconds=60):
        self.running = True
        
        # 여러 스레드로 데이터 생성
        threads = []
        for i in range(3):  # 3개 스레드
            thread = threading.Thread(
                target=self.simulate_user_activity,
                args=(f'simulator_{i}', duration_seconds)
            )
            threads.append(thread)
            thread.start()
        
        # 모든 스레드 완료 대기
        for thread in threads:
            thread.join()
            
        print("시뮬레이션 완료")
    
    def simulate_user_activity(self, simulator_id, duration):
        start_time = time.time()
        count = 0
        
        while time.time() - start_time < duration and self.running:
            # 랜덤 사용자 이벤트 생성
            event = {
                'timestamp': datetime.utcnow().isoformat(),
                'simulator_id': simulator_id,
                'user_id': random.randint(1000, 9999),
                'event_type': random.choice(['click', 'view', 'purchase']),
                'value': random.randint(1, 1000),
                'session_id': f'session_{random.randint(100, 999)}'
            }
            
            try:
                self.kinesis.put_record(
                    StreamName=self.stream_name,
                    Data=json.dumps(event),
                    PartitionKey=event['session_id']
                )
                count += 1
                
                if count % 10 == 0:
                    print(f"{simulator_id}: {count}개 이벤트 전송")
                    
            except Exception as e:
                print(f"전송 오류: {e}")
            
            # 100ms ~ 2초 랜덤 대기
            time.sleep(random.uniform(0.1, 2.0))

if __name__ == "__main__":
    simulator = KinesisSimulator('lab-data-stream')
    print("실시간 데이터 시뮬레이션 시작 (60초간)")
    simulator.start_simulation(60)
```

## 문제 해결

### 1. 일반적인 오류
```bash
# 스트림이 존재하지 않는 경우
aws kinesis describe-stream --stream-name lab-data-stream
# ResourceNotFoundException 발생 시 스트림 재생성

# 권한 오류 발생 시
aws iam get-user
aws iam list-attached-user-policies --user-name YOUR_USERNAME
```

### 2. 성능 문제 진단
```bash
# 스트림 메트릭 확인
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name WriteProvisionedThroughputExceeded \
    --dimensions Name=StreamName,Value=lab-data-stream \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
    --period 300 \
    --statistics Sum
```

## 정리 및 리소스 삭제

### 1. AWS CLI로 삭제
```bash
# 스트림 삭제
aws kinesis delete-stream --stream-name lab-data-stream

# 삭제 확인
aws kinesis describe-stream --stream-name lab-data-stream
# ResourceNotFoundException 발생하면 삭제 완료
```

### 2. Terraform으로 삭제
```bash
terraform destroy
```

## 실습 결과 확인

### 성공 기준
- [ ] Kinesis 스트림이 ACTIVE 상태로 생성됨
- [ ] 데이터 전송 및 수신이 정상 작동함
- [ ] CloudWatch에서 메트릭 확인 가능
- [ ] 배치 전송이 성공적으로 수행됨
- [ ] 실시간 시뮬레이션이 원활히 실행됨

### 학습 포인트
* Kinesis 스트림의 기본 구성 요소 이해
* 샤드 관리 및 스케일링 방법
* 데이터 전송 방식 (단일 vs 배치)
* 파티션 키의 중요성
* CloudWatch를 통한 모니터링

## 다음 단계
이 실습을 완료한 후에는:
1. **2.2.1**: 다양한 데이터 소스에서 Kinesis로 데이터 전송
2. **2.2.2**: Kinesis Analytics를 통한 실시간 분석
3. **2.2.3**: S3/EMR 연동 파이프라인 구축

으로 진행하세요.
