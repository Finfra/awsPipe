# 2.1.3 실습: Kinesis Data Streams 생성

## 실습 목표
* AWS CLI와 Terraform을 사용하여 Kinesis Data Streams 생성
* 스트림 설정 및 구성 최적화
* 기본적인 데이터 전송 및 수신 테스트
* 모니터링 및 관리 방법 습득

## 사전 요구사항
* AWS CLI 설치 및 구성
* Terraform 설치 (>= 1.0)
* 적절한 IAM 권한 보유
* jq 설치 (JSON 파싱용)

## 실습 환경 설정

### 1. 필수 도구 확인
```bash
# AWS CLI 버전 확인
aws --version

# Terraform 버전 확인
terraform --version

# jq 설치 확인
jq --version

# AWS 자격 증명 확인
aws sts get-caller-identity
```

### 2. 실습 디렉토리 설정
```bash
mkdir kinesis-lab
cd kinesis-lab
```

## 방법 1: AWS CLI로 Kinesis 스트림 생성

### 1. 기본 스트림 생성
```bash
# 스트림 생성 (2개 샤드)
aws kinesis create-stream \
    --stream-name lab-data-stream \
    --shard-count 2

# 스트림 상태 확인
aws kinesis describe-stream \
    --stream-name lab-data-stream
```

### 2. 스트림 활성화 대기
```bash
# 스트림이 ACTIVE 상태가 될 때까지 대기
while true; do
    STATUS=$(aws kinesis describe-stream \
        --stream-name lab-data-stream \
        --query 'StreamDescription.StreamStatus' \
        --output text)
    
    echo "스트림 상태: $STATUS"
    
    if [ "$STATUS" = "ACTIVE" ]; then
        echo "✅ 스트림 활성화 완료"
        break
    fi
    
    sleep 10
done
```

### 3. 스트림 설정 조정
```bash
# 데이터 보존 기간 설정 (24시간 → 168시간)
aws kinesis increase-stream-retention-period \
    --stream-name lab-data-stream \
    --retention-period-hours 168

# 샤드 레벨 메트릭 활성화
aws kinesis enable-enhanced-monitoring \
    --stream-name lab-data-stream \
    --shard-level-metrics IncomingRecords,OutgoingRecords
```

## 방법 2: Terraform으로 인프라 구성

### Terraform 파일 구조
소스 파일: `2.1.3.src/`
* `main.tf` - 메인 리소스 정의
* `terraform-variables.tf` - 변수 정의
* `terraform-outputs.tf` - 출력 정의

### Terraform 실행
```bash
# 소스 파일 복사
cp 2.1.3.src/*.tf .

# 초기화
terraform init

# 실행 계획 확인
terraform plan

# 인프라 생성
terraform apply
```

## 실습 3: 데이터 전송 및 수신 테스트

### 1. 테스트 데이터 전송
실행: `python 2.1.3.src/producer.py [stream_name] [record_count]`

```bash
# 기본 테스트 (10개 레코드)
python 2.1.3.src/producer.py lab-data-stream 10

# 대량 테스트 (100개 레코드)
python 2.1.3.src/producer.py lab-data-stream 100
```

주요 기능:
* 순차적 테스트 데이터 생성
* 파티션 키 기반 분산
* 전송 상태 실시간 확인
* 오류 처리 및 재시도

### 2. 데이터 수신 테스트
실행: `python 2.1.3.src/consumer.py [stream_name]`

```bash
# 데이터 수신 테스트
python 2.1.3.src/consumer.py lab-data-stream
```

주요 기능:
* 모든 샤드에서 데이터 읽기
* TRIM_HORIZON부터 순차 처리
* JSON 데이터 파싱 및 출력

### 3. 배치 전송 테스트
실행: `python 2.1.3.src/batch_producer.py [stream_name] [batch_size]`

```bash
# 배치 전송 테스트 (100개 레코드)
python 2.1.3.src/batch_producer.py lab-data-stream 100

# 대용량 배치 (500개 레코드)
python 2.1.3.src/batch_producer.py lab-data-stream 500
```

배치 전송 장점:
* 높은 처리량 (최대 500개/요청)
* API 호출 비용 절감
* 자동 실패 처리 및 재시도

## 실습 4: 모니터링 및 관리

### 1. CloudWatch 메트릭 확인
```bash
# 스트림 메트릭 조회
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=lab-data-stream \
    --start-time 2024-05-26T09:00:00Z \
    --end-time 2024-05-26T10:00:00Z \
    --period 300 \
    --statistics Sum
```

### 2. 스트림 관리 명령어
```bash
# 스트림 상세 정보
aws kinesis describe-stream \
    --stream-name lab-data-stream \
    --query 'StreamDescription.{
        Name:StreamName,
        Status:StreamStatus,
        Shards:Shards[].ShardId,
        RetentionPeriod:RetentionPeriodHours
    }'

# 샤드 목록 조회
aws kinesis list-shards \
    --stream-name lab-data-stream

# 스트림 태그 확인
aws kinesis list-tags-for-stream \
    --stream-name lab-data-stream
```

### 3. 스케일링 테스트
```bash
# 샤드 수 증가 (2 → 4)
aws kinesis update-shard-count \
    --stream-name lab-data-stream \
    --target-shard-count 4 \
    --scaling-type UNIFORM_SCALING

# 스케일링 상태 확인
aws kinesis describe-stream \
    --stream-name lab-data-stream \
    --query 'StreamDescription.StreamStatus'
```

## 실습 5: 고급 기능 테스트

### 1. 실시간 데이터 시뮬레이션
실행: `python 2.1.3.src/realtime_simulator.py [stream_name] [duration]`

```bash
# 60초간 실시간 시뮬레이션
python 2.1.3.src/realtime_simulator.py lab-data-stream 60

# 5분간 부하 테스트
python 2.1.3.src/realtime_simulator.py lab-data-stream 300
```

시뮬레이션 특징:
* 다중 스레드 병렬 처리
* 다양한 이벤트 타입 생성
* 랜덤 시간 간격 전송
* 실시간 상태 모니터링

### 2. 스트림 상태 모니터링
```bash
# 실시간 메트릭 확인 (별도 터미널)
watch -n 5 'aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name IncomingRecords \
    --dimensions Name=StreamName,Value=lab-data-stream \
    --start-time $(date -u -d "5 minutes ago" +%Y-%m-%dT%H:%M:%SZ) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
    --period 60 \
    --statistics Sum \
    --query "Datapoints[0].Sum"'
```

## 문제 해결

### 1. 일반적인 오류 해결
```bash
# 스트림 존재 확인
aws kinesis describe-stream --stream-name lab-data-stream
# ResourceNotFoundException 발생 시 스트림 재생성

# 권한 확인
aws iam get-user
aws iam list-attached-user-policies --user-name YOUR_USERNAME

# 리전 확인
aws configure get region
```

### 2. 성능 문제 진단
```bash
# 스로틀링 확인
aws cloudwatch get-metric-statistics \
    --namespace AWS/Kinesis \
    --metric-name WriteProvisionedThroughputExceeded \
    --dimensions Name=StreamName,Value=lab-data-stream \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
    --period 300 \
    --statistics Sum
```

### 3. 디버깅 도구
```python
# 간단한 연결 테스트
import boto3

def test_kinesis_connection():
    try:
        kinesis = boto3.client('kinesis')
        streams = kinesis.list_streams()
        print("✅ Kinesis 연결 성공")
        print(f"사용 가능한 스트림: {streams['StreamNames']}")
    except Exception as e:
        print(f"❌ 연결 실패: {e}")

test_kinesis_connection()
```

## 정리 및 리소스 삭제

### 1. AWS CLI로 삭제
```bash
# 스트림 삭제
aws kinesis delete-stream --stream-name lab-data-stream

# 삭제 확인 (ResourceNotFoundException 발생하면 삭제 완료)
aws kinesis describe-stream --stream-name lab-data-stream
```

### 2. Terraform으로 삭제
```bash
terraform destroy
```

## 실습 결과 확인

### 성공 기준
- [ ] Kinesis 스트림이 ACTIVE 상태로 생성됨
- [ ] 데이터 전송 및 수신이 정상 작동함
- [ ] CloudWatch에서 메트릭 확인 가능
- [ ] 배치 전송이 성공적으로 수행됨
- [ ] 실시간 시뮬레이션이 원활히 실행됨

### 성능 벤치마크
| 테스트 유형 | 목표 처리량 | 예상 지연시간 | 성공률 |
|-------------|-------------|---------------|--------|
| 단일 전송 | 100 레코드/분 | < 100ms | > 99% |
| 배치 전송 | 500 레코드/요청 | < 500ms | > 99.5% |
| 실시간 시뮬레이션 | 1000+ 레코드/분 | < 200ms | > 98% |

### 학습 포인트
* Kinesis 스트림의 기본 구성 요소 이해
* 샤드 관리 및 스케일링 방법
* 데이터 전송 방식 (단일 vs 배치)
* 파티션 키의 중요성과 분산 효과
* CloudWatch를 통한 실시간 모니터링
* 성능 최적화 및 문제 해결 방법

## 다음 단계

이 실습을 완료한 후에는:

### 2.2 단계로 진행
1. **2.2.1**: 다양한 데이터 소스에서 Kinesis로 데이터 수집
2. **2.2.2**: Kinesis Data Analytics를 통한 실시간 분석  
3. **2.2.3**: Lambda 함수와 연동한 실시간 처리

### 고급 주제 탐색
* Kinesis Client Library (KCL) 활용
* 멀티 리전 복제 전략
* 데이터 변환 및 압축
* 보안 및 암호화 설정

### 추가 리소스
* [AWS Kinesis 개발자 가이드](https://docs.aws.amazon.com/kinesis/)
* [Kinesis 베스트 프랙티스](https://aws.amazon.com/kinesis/data-streams/faqs/)
* [AWS SDK for Python (Boto3) 문서](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/kinesis.html)
