# 1.2 파티션 및 샤드 관리

## Kafka 파티션 vs Kinesis 샤드

### 개념 비교
| 측면 | Kafka 파티션 | Kinesis 샤드 |
|------|--------------|--------------|
| **처리량** | 파티션당 무제한 | 샤드당 1MB/초 또는 1000 레코드/초 |
| **스케일링** | 수동 파티션 추가 | 자동/수동 샤드 분할/병합 |
| **비용** | 파티션 수 무관 | 샤드당 시간 단위 과금 |
| **복제** | 복제 팩터 설정 | 자동 3개 AZ 복제 |
| **순서 보장** | 파티션 내 순서 보장 | 샤드 내 순서 보장 |

## 샤드 관리 전략

### 소스 파일 구조
* `2.1.2.src/shard_calculator.py` - 샤드 수 계산 도구
* `2.1.2.src/shard_manager.py` - 동적 샤드 스케일링 관리
* `2.1.2.src/partition_key_tester.py` - 파티션 키 분산 테스트
* `2.1.2.src/kinesis-streams-terraform.tf` - Terraform 인프라 코드

### 1. 샤드 계산 방법
실행: `python 2.1.2.src/shard_calculator.py`

주요 기능:
* 처리량 기준 샤드 수 계산
* 레코드 수 기준 계산
* 파티션 키 기준 계산
* 비용 추정 및 버퍼 고려

계산 예시 코드:
```python
import math

def calculate_required_shards(requirements):
    """필요한 샤드 수 계산"""
    
    # 처리량 기준 계산
    throughput_shards = math.ceil(requirements['mb_per_second'] / 1.0)  # 1MB/초 제한
    
    # 레코드 수 기준 계산
    records_shards = math.ceil(requirements['records_per_second'] / 1000)  # 1000 레코드/초 제한
    
    # 파티션 키 기준 계산 (순서 보장)
    partition_shards = requirements.get('partition_keys', 1)
    
    # 최대값 선택
    required_shards = max(throughput_shards, records_shards, partition_shards)
    
    # 향후 확장성을 위한 버퍼 (20% 추가)
    buffered_shards = math.ceil(required_shards * 1.2)
    
    return {
        'minimum_shards': required_shards,
        'recommended_shards': buffered_shards,
        'throughput_based': throughput_shards,
        'records_based': records_shards,
        'partition_based': partition_shards,
        'estimated_cost_per_hour': buffered_shards * 0.015
    }

# 사용 예시
requirements = {
    'mb_per_second': 3.5,
    'records_per_second': 2500,
    'partition_keys': 4  # 4개의 서로 다른 파티션 키
}

shard_plan = calculate_required_shards(requirements)
print(f"권장 샤드 수: {shard_plan['recommended_shards']}")
print(f"시간당 예상 비용: ${shard_plan['estimated_cost_per_hour']:.2f}")
```

### 2. 동적 샤드 스케일링
실행: `python 2.1.2.src/shard_manager.py <stream_name> [action]`

사용 예시:
```bash
# 자동 스케일링 실행
python 2.1.2.src/shard_manager.py my-stream auto_scale

# 스트림 상태 확인
python 2.1.2.src/shard_manager.py my-stream status

# 수동 스케일 아웃
python 2.1.2.src/shard_manager.py my-stream scale_out
```

주요 기능:
```python
import boto3
import time
from datetime import datetime, timedelta

class KinesisShardManager:
    def __init__(self, stream_name):
        self.kinesis = boto3.client('kinesis')
        self.cloudwatch = boto3.client('cloudwatch')
        self.stream_name = stream_name
    
    def get_stream_metrics(self, minutes=5):
        """스트림 메트릭 조회"""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(minutes=minutes)
        
        # 처리량 메트릭 조회
        response = self.cloudwatch.get_metric_statistics(
            Namespace='AWS/Kinesis',
            MetricName='IncomingBytes',
            Dimensions=[
                {'Name': 'StreamName', 'Value': self.stream_name}
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=60,  # 1분 단위
            Statistics=['Average', 'Maximum']
        )
        
        if not response['Datapoints']:
            return {'avg_bytes_per_sec': 0, 'max_bytes_per_sec': 0}
        
        # 바이트/초로 변환
        avg_bytes = sum(dp['Average'] for dp in response['Datapoints']) / len(response['Datapoints'])
        max_bytes = max(dp['Maximum'] for dp in response['Datapoints'])
        
        return {
            'avg_bytes_per_sec': avg_bytes,
            'max_bytes_per_sec': max_bytes
        }
    
    def auto_scale(self):
        """자동 스케일링 실행"""
        print(f"자동 스케일링 확인: {self.stream_name}")
        
        metrics = self.get_stream_metrics()
        current_shards = self.get_current_shard_count()
        
        print(f"현재 샤드 수: {current_shards}")
        print(f"평균 처리량: {metrics['avg_bytes_per_sec']/1024/1024:.2f} MB/초")
        print(f"최대 처리량: {metrics['max_bytes_per_sec']/1024/1024:.2f} MB/초")
        
        if self.should_scale_out(metrics):
            self.scale_out()
        elif self.should_scale_in(metrics):
            self.scale_in()
        else:
            print("스케일링 불필요")
```

## 파티션 키 전략

### 파티션 키 분산 테스트
실행: `python 2.1.2.src/partition_key_tester.py [strategy_name]`

사용 예시:
```bash
# 모든 전략 비교
python 2.1.2.src/partition_key_tester.py compare

# 특정 전략 테스트
python 2.1.2.src/partition_key_tester.py hash_based_key
```

### 1. 효과적인 파티션 키 설계
```python
import hashlib
import uuid
from datetime import datetime

class PartitionKeyStrategy:
    @staticmethod
    def user_based_key(user_id):
        """사용자 기반 파티션 키 - 사용자별 순서 보장"""
        return str(user_id)
    
    @staticmethod
    def hash_based_key(identifier):
        """해시 기반 파티션 키 - 균등 분산"""
        return hashlib.md5(str(identifier).encode()).hexdigest()
    
    @staticmethod
    def time_based_key(timestamp, buckets=10):
        """시간 기반 파티션 키 - 시간대별 분산"""
        minute_bucket = (timestamp.minute // (60 // buckets))
        return f"{timestamp.hour:02d}_{minute_bucket:02d}"
    
    @staticmethod
    def composite_key(user_id, category):
        """복합 파티션 키 - 사용자+카테고리별 순서 보장"""
        return f"{user_id}_{category}"
    
    @staticmethod
    def random_key():
        """완전 랜덤 키 - 최대 분산"""
        return str(uuid.uuid4())

# 파티션 키 분산 테스트
def test_partition_distribution(key_generator, sample_size=10000):
    """파티션 키 분산 테스트"""
    keys = {}
    
    for i in range(sample_size):
        if key_generator == PartitionKeyStrategy.user_based_key:
            key = key_generator(i % 100)  # 100명의 사용자
        elif key_generator == PartitionKeyStrategy.time_based_key:
            key = key_generator(datetime.now())
        else:
            key = key_generator(i)
        
        # 해시값을 샤드 수로 나눈 나머지로 분산 계산
        shard_id = int(hashlib.md5(key.encode()).hexdigest(), 16) % 4
        keys[shard_id] = keys.get(shard_id, 0) + 1
    
    print(f"파티션 키 분산 결과 ({key_generator.__name__}):")
    for shard_id, count in sorted(keys.items()):
        percentage = (count / sample_size) * 100
        print(f"  샤드 {shard_id}: {count:,} ({percentage:.1f}%)")
    
    # 분산 균등성 계산 (표준편차)
    values = list(keys.values())
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)
    std_dev = variance ** 0.5
    cv = (std_dev / mean) * 100  # 변동계수
    
    print(f"  분산 균등성: {cv:.1f}% (낮을수록 균등)")
    return cv

# 테스트 실행
print("=== 파티션 키 전략별 분산 테스트 ===")
test_partition_distribution(PartitionKeyStrategy.hash_based_key)
test_partition_distribution(PartitionKeyStrategy.user_based_key)
test_partition_distribution(PartitionKeyStrategy.random_key)
```

### 2. 핫 샤드 감지 및 해결
```python
class HotShardDetector:
    def __init__(self, stream_name):
        self.kinesis = boto3.client('kinesis')
        self.cloudwatch = boto3.client('cloudwatch')
        self.stream_name = stream_name
    
    def detect_hot_shards(self):
        """핫 샤드 감지"""
        
        # 각 샤드별 메트릭 조회
        stream_desc = self.kinesis.describe_stream(StreamName=self.stream_name)
        shards = stream_desc['StreamDescription']['Shards']
        
        shard_metrics = {}
        
        for shard in shards:
            if shard.get('SequenceNumberRange', {}).get('EndingSequenceNumber'):
                continue  # 비활성 샤드 제외
            
            shard_id = shard['ShardId']
            
            # 샤드별 처리량 조회
            response = self.cloudwatch.get_metric_statistics(
                Namespace='AWS/Kinesis',
                MetricName='IncomingBytes',
                Dimensions=[
                    {'Name': 'StreamName', 'Value': self.stream_name},
                    {'Name': 'ShardId', 'Value': shard_id}
                ],
                StartTime=datetime.utcnow() - timedelta(minutes=10),
                EndTime=datetime.utcnow(),
                Period=300,  # 5분 단위
                Statistics=['Average']
            )
            
            if response['Datapoints']:
                avg_bytes = sum(dp['Average'] for dp in response['Datapoints']) / len(response['Datapoints'])
                shard_metrics[shard_id] = avg_bytes / 1024 / 1024  # MB/초
        
        if not shard_metrics:
            return []
        
        # 평균 대비 2배 이상인 샤드를 핫 샤드로 판단
        avg_throughput = sum(shard_metrics.values()) / len(shard_metrics)
        hot_threshold = avg_throughput * 2
        
        hot_shards = [
            (shard_id, throughput) 
            for shard_id, throughput in shard_metrics.items() 
            if throughput > hot_threshold
        ]
        
        return hot_shards
    
    def suggest_partition_key_fix(self, hot_shards):
        """파티션 키 개선 제안"""
        
        if not hot_shards:
            print("핫 샤드가 감지되지 않음")
            return
        
        print("🔥 핫 샤드 감지됨!")
        for shard_id, throughput in hot_shards:
            print(f"  샤드 {shard_id}: {throughput:.2f} MB/초")
        
        print("\n💡 개선 제안:")
        print("1. 파티션 키에 랜덤 요소 추가")
        print("   ex) user_id -> user_id + random_suffix")
        
        print("\n2. 복합 파티션 키 사용")
        print("   ex) user_id -> user_id + timestamp_bucket")
        
        print("\n3. 해시 기반 파티션 키로 변경")
        print("   ex) md5(user_id + event_type)")

# 사용 예시
detector = HotShardDetector('my-stream')
hot_shards = detector.detect_hot_shards()
detector.suggest_partition_key_fix(hot_shards)
```

## 성능 최적화

### 1. 배치 처리 최적화
```python
import boto3
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

class OptimizedKinesisProducer:
    def __init__(self, stream_name, max_workers=10):
        self.kinesis = boto3.client('kinesis')
        self.stream_name = stream_name
        self.max_workers = max_workers
        self.batch_size = 500  # 배치당 레코드 수
        
    def put_records_batch(self, records):
        """배치 단위로 레코드 전송"""
        
        # Kinesis put_records는 최대 500개 레코드까지 지원
        batch_records = []
        for i, record in enumerate(records):
            batch_records.append({
                'Data': json.dumps(record['data']) if isinstance(record['data'], dict) else record['data'],
                'PartitionKey': record['partition_key']
            })
            
            # 배치 크기에 도달하거나 마지막 레코드인 경우 전송
            if len(batch_records) == self.batch_size or i == len(records) - 1:
                try:
                    response = self.kinesis.put_records(
                        Records=batch_records,
                        StreamName=self.stream_name
                    )
                    
                    # 실패한 레코드 확인
                    failed_count = response['FailedRecordCount']
                    if failed_count > 0:
                        print(f"배치 전송 중 {failed_count}개 레코드 실패")
                        
                        # 실패한 레코드 재시도
                        failed_records = []
                        for j, record_result in enumerate(response['Records']):
                            if 'ErrorCode' in record_result:
                                failed_records.append(batch_records[j])
                        
                        if failed_records:
                            self._retry_failed_records(failed_records)
                    
                    print(f"배치 전송 완료: {len(batch_records) - failed_count}개 성공")
                    
                except Exception as e:
                    print(f"배치 전송 오류: {e}")
                
                batch_records = []  # 배치 초기화
    
    def _retry_failed_records(self, failed_records, max_retries=3):
        """실패한 레코드 재시도"""
        
        for attempt in range(max_retries):
            if not failed_records:
                break
                
            print(f"재시도 {attempt + 1}/{max_retries}: {len(failed_records)}개 레코드")
            
            try:
                response = self.kinesis.put_records(
                    Records=failed_records,
                    StreamName=self.stream_name
                )
                
                # 여전히 실패한 레코드만 다음 재시도에 포함
                still_failed = []
                for i, record_result in enumerate(response['Records']):
                    if 'ErrorCode' in record_result:
                        still_failed.append(failed_records[i])
                
                failed_records = still_failed
                
                # 지수 백오프
                if failed_records and attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                    
            except Exception as e:
                print(f"재시도 {attempt + 1} 오류: {e}")
                time.sleep(2 ** attempt)
        
        if failed_records:
            print(f"최종 실패: {len(failed_records)}개 레코드")
    
    def send_data_parallel(self, all_records):
        """병렬 처리로 데이터 전송"""
        
        # 레코드를 청크로 분할
        chunks = [
            all_records[i:i + self.batch_size] 
            for i in range(0, len(all_records), self.batch_size)
        ]
        
        print(f"총 {len(chunks)}개 청크로 분할하여 병렬 처리")
        
        # 병렬 실행
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_chunk = {
                executor.submit(self.put_records_batch, chunk): chunk 
                for chunk in chunks
            }
            
            completed = 0
            for future in as_completed(future_to_chunk):
                try:
                    future.result()
                    completed += 1
                    print(f"진행률: {completed}/{len(chunks)} ({completed/len(chunks)*100:.1f}%)")
                except Exception as e:
                    print(f"청크 처리 오류: {e}")

# 사용 예시
def generate_sample_records(count=10000):
    """샘플 레코드 생성"""
    import random
    
    records = []
    for i in range(count):
        records.append({
            'data': {
                'user_id': random.randint(1, 1000),
                'event_type': random.choice(['click', 'view', 'purchase']),
                'timestamp': int(time.time()),
                'value': random.uniform(10, 500)
            },
            'partition_key': PartitionKeyStrategy.hash_based_key(f"user_{random.randint(1, 1000)}")
        })
    
    return records

# 성능 테스트
producer = OptimizedKinesisProducer('test-stream', max_workers=5)
sample_records = generate_sample_records(5000)

start_time = time.time()
producer.send_data_parallel(sample_records)
end_time = time.time()

print(f"총 처리 시간: {end_time - start_time:.2f}초")
print(f"처리율: {len(sample_records)/(end_time - start_time):.0f} 레코드/초")
```

## 모니터링 및 알람

### 1. 종합 모니터링 대시보드
```python
import boto3
import json

def create_kinesis_dashboard(stream_name):
    """Kinesis 스트림 모니터링 대시보드 생성"""
    
    cloudwatch = boto3.client('cloudwatch')
    
    dashboard_body = {
        "widgets": [
            {
                "type": "metric",
                "properties": {
                    "metrics": [
                        ["AWS/Kinesis", "IncomingRecords", "StreamName", stream_name],
                        [".", "IncomingBytes", ".", "."],
                        [".", "OutgoingRecords", ".", "."],
                        [".", "OutgoingBytes", ".", "."]
                    ],
                    "period": 300,
                    "stat": "Sum", 
                    "region": "us-east-1",
                    "title": "스트림 처리량"
                }
            },
            {
                "type": "metric",
                "properties": {
                    "metrics": [
                        ["AWS/Kinesis", "WriteProvisionedThroughputExceeded", "StreamName", stream_name],
                        [".", "ReadProvisionedThroughputExceeded", ".", "."],
                        [".", "UserRecordsPending", ".", "."]
                    ],
                    "period": 300,
                    "stat": "Sum",
                    "region": "us-east-1", 
                    "title": "오류 및 제한"
                }
            }
        ]
    }
    
    response = cloudwatch.put_dashboard(
        DashboardName=f'Kinesis-{stream_name}',
        DashboardBody=json.dumps(dashboard_body)
    )
    
    print(f"대시보드 생성 완료: Kinesis-{stream_name}")
    return response

def setup_kinesis_alarms(stream_name, sns_topic_arn):
    """Kinesis 알람 설정"""
    
    cloudwatch = boto3.client('cloudwatch')
    
    alarms = [
        {
            'name': f'{stream_name}-HighIncomingRecords',
            'description': '높은 수신 레코드 수',
            'metric_name': 'IncomingRecords',
            'threshold': 10000,
            'comparison': 'GreaterThanThreshold'
        },
        {
            'name': f'{stream_name}-WriteThrottling',
            'description': '쓰기 스로틀링 발생',
            'metric_name': 'WriteProvisionedThroughputExceeded',
            'threshold': 0,
            'comparison': 'GreaterThanThreshold'
        },
        {
            'name': f'{stream_name}-ReadThrottling',
            'description': '읽기 스로틀링 발생',
            'metric_name': 'ReadProvisionedThroughputExceeded',
            'threshold': 0,
            'comparison': 'GreaterThanThreshold'
        }
    ]
    
    for alarm in alarms:
        cloudwatch.put_metric_alarm(
            AlarmName=alarm['name'],
            AlarmDescription=alarm['description'],
            ComparisonOperator=alarm['comparison'],
            EvaluationPeriods=2,
            MetricName=alarm['metric_name'],
            Namespace='AWS/Kinesis',
            Period=300,
            Statistic='Sum',
            Threshold=alarm['threshold'],
            ActionsEnabled=True,
            AlarmActions=[sns_topic_arn],
            Dimensions=[
                {
                    'Name': 'StreamName',
                    'Value': stream_name
                }
            ]
        )
        
        print(f"알람 생성: {alarm['name']}")

# 모니터링 설정 실행
create_kinesis_dashboard('my-stream')
setup_kinesis_alarms('my-stream', 'arn:aws:sns:us-east-1:123456789012:kinesis-alerts')
```

## 권장사항

### 샤드 관리 베스트 프랙티스
* **적절한 샤드 수**: 처리량과 비용의 균형점 찾기
* **파티션 키 설계**: 균등 분산과 순서 보장 요구사항 고려
* **모니터링**: 지속적인 성능 및 비용 추적
* **자동화**: 스케일링 및 알람 자동화로 운영 효율성 향상

### 주의사항
* **샤드 분할/병합 시간**: 완료까지 수 분 소요
* **순서 보장**: 파티션 키가 같은 레코드만 순서 보장
* **처리량 제한**: 샤드당 1MB/초 또는 1000 레코드/초
* **비용 최적화**: 불필요한 샤드는 즉시 병합
