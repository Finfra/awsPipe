# 1.2.3. 데이터 레이크 아키텍처 설계

## 3계층 데이터 레이크 아키텍처

### Bronze Layer (Raw Zone)
* **목적**: 원본 데이터를 변경 없이 저장
* **저장 형식**: JSON, CSV, 로그 파일 등 원본 형식 유지
* **특징**: 데이터 불변성 보장, 모든 소스 데이터 보존

### Silver Layer (Refined Zone)
* **목적**: 정제되고 표준화된 데이터
* **저장 형식**: Parquet (스키마 적용, 압축 최적화)
* **특징**: 데이터 품질 검증, 중복 제거, 표준화

### Gold Layer (Curated Zone)
* **목적**: 비즈니스 로직이 적용된 최종 데이터
* **저장 형식**: 집계 테이블, 리포트용 사전 계산 데이터
* **특징**: 비즈니스 규칙 적용, 분석 최적화

## 폴더 구조 설계

```
s3://datalake-bucket/
├── bronze/                    # 원본 데이터
│   ├── events/
│   │   └── year=2024/month=05/day=26/
│   ├── logs/
│   └── raw-files/
├── silver/                    # 정제된 데이터
│   ├── events/
│   │   └── year=2024/month=05/
│   ├── users/
│   └── transactions/
└── gold/                      # 비즈니스 데이터
    ├── analytics/
    │   ├── daily-metrics/
    │   └── user-summary/
    └── reports/
```

## 파티셔닝 전략

### 시간 기반 파티셔닝
* **목적**: 쿼리 성능 향상 및 비용 최적화
* **구조**: `year=YYYY/month=MM/day=DD/`
* **장점**: 특정 기간 데이터만 스캔, 라이프사이클 관리 용이

### 카테고리 기반 파티셔닝
* **목적**: 업무 도메인별 데이터 분리
* **구조**: `region=asia/product_type=mobile/`
* **장점**: 특정 카테고리 분석 시 성능 향상

## 데이터 거버넌스

### 메타데이터 관리
* **AWS Glue Data Catalog**: 테이블 스키마 및 파티션 정보 관리
* **데이터 계보**: 데이터 출처 및 변환 이력 추적
* **스키마 진화**: 하위 호환성을 유지하며 스키마 변경

### 접근 제어
* **IAM 정책**: 계층별 접근 권한 분리
* **S3 버킷 정책**: 세밀한 리소스 단위 접근 제어
* **AWS Lake Formation**: 테이블/컬럼 레벨 권한 관리

## 데이터 처리 플로우

### Bronze → Silver 변환
1. **데이터 검증**: 스키마 유효성, 필수 필드 확인
2. **정제 작업**: NULL 값 처리, 중복 제거, 데이터 타입 변환
3. **표준화**: 명명 규칙 적용, 포맷 통일
4. **품질 검사**: 비즈니스 룰 기반 데이터 품질 검증

### Silver → Gold 변환
1. **비즈니스 로직 적용**: 계산 필드 생성, 집계 규칙 적용
2. **성능 최적화**: 자주 사용되는 집계 테이블 사전 계산
3. **리포팅 최적화**: BI 도구에 최적화된 형태로 변환

## 성능 최적화 전략

### 파일 포맷 최적화
* **Parquet**: 컬럼형 저장으로 압축률 높음, 쿼리 성능 우수
* **압축**: Snappy(빠른 읽기) vs GZIP(높은 압축률)
* **파일 크기**: 128MB-1GB 권장 (너무 작으면 메타데이터 오버헤드)

### 쿼리 최적화
* **파티션 프루닝**: WHERE 조건으로 불필요한 파티션 제외
* **컬럼 프로젝션**: 필요한 컬럼만 읽기
* **조건절 푸시다운**: 스토리지 레벨에서 필터링

## 비용 최적화

### 스토리지 클래스 전략
* **Standard**: 자주 접근하는 현재 데이터 (Gold Layer)
* **Standard-IA**: 가끔 접근하는 데이터 (Silver Layer 일부)
* **Glacier**: 아카이브 데이터 (Bronze Layer 과거 데이터)

### 라이프사이클 정책
* **30일**: Standard → Standard-IA
* **90일**: Standard-IA → Glacier
* **365일**: Glacier → Deep Archive

## 데이터 품질 관리

### 품질 차원
* **완전성**: 필수 데이터 누락 여부
* **정확성**: 비즈니스 룰 준수 여부
* **일관성**: 데이터 형식 및 값 범위 일치
* **유효성**: 참조 무결성 및 제약 조건 확인

### 모니터링 지표
* **데이터 볼륨**: 계층별 데이터 크기 추이
* **처리 지연**: 배치 작업 완료 시간
* **품질 점수**: 검증 룰 통과율
* **에러율**: 처리 실패 및 재시도 비율

## 보안 및 컴플라이언스

### 암호화
* **전송 중 암호화**: HTTPS/SSL
* **저장 중 암호화**: S3 SSE (AES-256)
* **키 관리**: AWS KMS 통합

### 데이터 마스킹
* **PII 데이터**: 개인정보 식별 및 마스킹
* **민감 정보**: 업무 규칙에 따른 데이터 보호
* **익명화**: 분석용 데이터의 개인 식별 정보 제거

## 모니터링 및 알림

### CloudWatch 메트릭
* **스토리지 사용량**: 계층별 데이터 크기
* **API 호출 수**: S3 GET/PUT 요청 모니터링
* **비용 추적**: 일일/월별 비용 변화

### 알림 체계
* **데이터 품질 이슈**: 임계치 초과 시 알림
* **처리 지연**: SLA 위반 시 알림
* **비용 초과**: 예산 임계치 도달 시 알림

## 아키텍처 설계 원칙

### 확장성
* **수평 확장**: 파티션 추가로 용량 확장
* **서비스 분리**: 계층별 독립적 처리
* **API 기반**: 마이크로서비스 아키텍처 지원

### 유연성
* **스키마 진화**: 하위 호환성 유지
* **다양한 소스**: 배치/스트리밍 데이터 동시 지원
* **멀티 포맷**: 다양한 파일 형식 지원

### 신뢰성
* **데이터 복제**: 다중 AZ 복제
* **백업 전략**: 정기적 백업 및 복원 테스트
* **장애 복구**: 자동 장애 감지 및 복구


