# 1.2 Apache Spark → EMR 매핑

## 컴퓨팅 계층 비교

### Apache Spark vs Amazon EMR
| 구분          | Apache Spark    | Amazon EMR        |
| ------------- | --------------- | ----------------- |
| 클러스터 관리 | 수동 설치/구성  | 자동 프로비저닝   |
| 스케일링      | 수동 노드 관리  | 자동 스케일링     |
| 모니터링      | 별도 도구 설치  | CloudWatch 통합   |
| 업그레이드    | 수동 업그레이드 | 관리형 업그레이드 |
| 비용 최적화   | 상시 운영       | 작업별 클러스터   |
| 개발 환경     | 별도 설정       | Jupyter 통합      |

## EMR의 주요 장점

### 관리형 서비스
* **자동 프로비저닝**: 클러스터 설정 자동화
* **패치 관리**: 보안 업데이트 자동 적용  
* **모니터링**: CloudWatch 메트릭 자동 수집
* **백업**: HDFS 데이터 S3 자동 백업

### 비용 효율성
* **Spot 인스턴스**: 최대 90% 비용 절감
* **자동 종료**: 유휴 시간 최소화
* **탄력적 스케일링**: 워크로드에 따른 자동 확장/축소
* **예약 인스턴스**: 장기 사용 시 할인

### 통합성
* **S3 연동**: 네이티브 S3 지원
* **IAM 통합**: 세밀한 권한 관리
* **VPC 지원**: 네트워크 격리
* **다양한 도구**: Spark, Hadoop, Hive, Presto 등

## Spark 실행 모드 비교

### 온프레미스 Spark
```bash
# 스탠드얼론 모드
./bin/spark-submit \
  --master spark://master:7077 \
  --deploy-mode cluster \
  your-app.py

# YARN 모드
./bin/spark-submit \
  --master yarn \
  --deploy-mode cluster \
  your-app.py
```

### EMR에서 Spark
```bash
# EMR Step으로 제출
aws emr add-steps \
  --cluster-id j-XXXXX \
  --steps Type=Spark,Name="MySparkApp",\
ActionOnFailure=CONTINUE,\
Args=[--deploy-mode,cluster,s3://bucket/app.py]

# 직접 spark-submit
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  s3://bucket/your-app.py
```

## 성능 최적화 비교

### 온프레미스 최적화
```python
# 수동 설정 필요
spark = SparkSession.builder \
    .config("spark.executor.memory", "4g") \
    .config("spark.executor.cores", "2") \
    .config("spark.sql.shuffle.partitions", "200") \
    .getOrCreate()
```

### EMR 최적화
1. AWS CLI 사용 시
```bash
aws emr create-cluster \
  --name "MyCluster" \
  --release-label emr-6.15.0 \
  --applications Name=Spark \
  --ec2-attributes KeyName=myKey \
  --instance-type m5.xlarge \
  --instance-count 3 \
  --use-default-roles \
  --configurations file://spark-config.json
```
* spark-config.json 예시:
```json
{
  "Classification": "spark-defaults",
  "Properties": {
    "spark.sql.adaptive.enabled": "true",
    "spark.sql.adaptive.coalescePartitions.enabled": "true",
    "spark.dynamicAllocation.enabled": "true",
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
  }
}
```

## 개발 환경 비교

### 온프레미스 개발
* **Jupyter 설치**: 별도 설치 및 구성 필요
* **라이브러리 관리**: 수동 패키지 관리
* **디버깅**: 로그 파일 직접 확인
* **코드 배포**: 수동 배포 프로세스

### EMR 개발 환경
* **EMR Notebooks**: 관리형 Jupyter 환경
* **사전 설치**: 주요 라이브러리 사전 설치
* **CloudWatch**: 중앙화된 로그 관리
* **S3 통합**: 코드 및 데이터 자동 동기화

## 마이그레이션 전략

### 1단계: 호환성 평가
* **Spark 버전 확인**: EMR 지원 버전과 비교
* **라이브러리 의존성**: 필요한 패키지 목록 작성
* **코드 수정**: S3 경로 변경 등

### 2단계: 점진적 마이그레이션
```python
# 기존 코드
df = spark.read.parquet("hdfs://namenode:9000/data/")

# EMR 마이그레이션
df = spark.read.parquet("s3://bucket/data/")
```

### 3단계: 성능 튜닝
* **인스턴스 타입 선택**: 워크로드에 맞는 최적화
* **스토리지 최적화**: EBS vs 인스턴스 스토어
* **네트워크 대역폭**: 배치 크기 조정

## 비용 분석

### 온프레미스 비용 (연간)
* **하드웨어**: $50,000 (서버 8대)
* **전력**: $12,000 
* **인건비**: $80,000 (운영 인력)
* **총 비용**: $142,000

### EMR 비용 (연간, 동일 성능)
* **온디맨드**: $36,000 (연중 50% 가동률)
* **Spot 인스턴스**: $18,000 (50% 할인)
* **운영비**: $20,000 (관리 최소화)
* **총 비용**: $38,000

### ROI 계산
* **비용 절감**: 73% ($104,000 절약)
* **운영 효율성**: 관리 시간 80% 단축
* **확장성**: 필요시 즉시 확장 가능

## 실제 마이그레이션 사례

### 사례 1: 배치 처리 워크로드
* **기존**: 24시간 상시 운영 클러스터
* **마이그레이션 후**: 작업별 클러스터 생성/삭제
* **결과**: 60% 비용 절감, 99.9% 가용성

### 사례 2: 실시간 분석
* **기존**: Kafka + Spark Streaming
* **마이그레이션 후**: Kinesis + EMR
* **결과**: 운영 복잡도 50% 감소

## 권장사항

### EMR 선택 기준
* **배치 처리 중심**: 정기적인 대용량 처리
* **가변적 워크로드**: 처리량 변동이 큰 경우
* **빠른 개발**: 프로토타입 및 실험 환경
* **AWS 생태계**: 다른 AWS 서비스와 통합

### 온프레미스 유지 기준
* **실시간 처리**: 극도로 낮은 지연시간 필요
* **규정 준수**: 데이터 국경 간 이동 제한
* **기존 투자**: 최근 하드웨어 투자로 감가상각 필요
* **특수 요구사항**: 커스텀 하드웨어 의존성

## 참고 링크
- [Amazon EMR 공식 문서](https://docs.aws.amazon.com/ko_kr/emr/index.html)
- [Apache Spark 공식 문서](https://spark.apache.org/docs/latest/)
- [EMR에서 Spark 실행 가이드](https://docs.aws.amazon.com/ko_kr/emr/latest/ReleaseGuide/emr-spark.html)
- [EMR 비용 최적화](https://aws.amazon.com/ko/emr/pricing/)
