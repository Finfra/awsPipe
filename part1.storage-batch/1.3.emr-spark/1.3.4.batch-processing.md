# 1.3.4. 대용량 데이터 배치 처리

## 실습 목적
EMR과 Spark를 활용한 대용량 데이터 배치 처리 실습을 진행합니다.

## 실습 파일 안내
* batch-processing.py 
  - 기본 Spark 데이터 처리 작업
  - S3의 파티션된 데이터를 읽어서 집계 처리 후 결과를 S3에 저장

* emr-spark-job.py
  - 최적화된 Spark 데이터 처리 작업
  - 고급 최적화 기법들을 적용한 성능 향상된 데이터 처리

## 실습 방법
1. 제공된 Spark 예제 코드를 EMR 클러스터에서 실행합니다.
2. 데이터 처리 결과를 S3 등 외부 저장소에 저장합니다.
3. 처리 성능 및 결과를 분석합니다.

## 참고
- [Amazon EMR 공식 문서](https://docs.aws.amazon.com/ko_kr/emr/index.html)
