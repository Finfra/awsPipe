# ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜ (JSONL íŒŒí‹°ì…˜ ë°ì´í„°ìš©)
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import ipywidgets as widgets
from IPython.display import display, clear_output
import time
from datetime import datetime
from pyspark.sql.functions import col, sum, count, hour, desc, date_format, to_date

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def visualize_trends(spark_df, date_col="timestamp", value_col="amount", category_col="category", limit=1000):
    """ì‹œê³„ì—´ íŠ¸ë Œë“œ ì‹œê°í™” - JSONL ë°ì´í„°ìš©"""
    
    # timestampë¥¼ dateë¡œ ë³€í™˜
    df_with_date = spark_df.withColumn("date", date_format(to_date(col(date_col)), "yyyy-MM-dd"))
    
    # ì¼ë³„ ì§‘ê³„
    if category_col and category_col in spark_df.columns:
        daily_stats = df_with_date \
            .groupBy("date", category_col) \
            .agg(
                sum(value_col).alias("total_value"),
                count("*").alias("count")
            ) \
            .orderBy("date")
    else:
        daily_stats = df_with_date \
            .groupBy("date") \
            .agg(
                sum(value_col).alias("total_value"),
                count("*").alias("count")
            ) \
            .orderBy("date")
    
    # Pandasë¡œ ë³€í™˜ (ì œí•œëœ ë°ì´í„°ì…‹)
    pandas_df = daily_stats.limit(limit).toPandas()
    
    # ì‹œê°í™”
    plt.figure(figsize=(15, 8))
    
    if category_col and category_col in pandas_df.columns:
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë“œ
        categories = pandas_df[category_col].unique()
        for i, category in enumerate(categories[:5]):  # ìµœëŒ€ 5ê°œ ì¹´í…Œê³ ë¦¬
            category_data = pandas_df[pandas_df[category_col] == category]
            plt.plot(category_data["date"], category_data["total_value"], 
                    label=category, marker='o', linewidth=2)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    else:
        plt.plot(pandas_df["date"], pandas_df["total_value"], 
                marker='o', linewidth=3, color='#2E86AB')
    
    plt.title(f'{value_col} ì‹œê³„ì—´ íŠ¸ë Œë“œ', fontsize=16, fontweight='bold')
    plt.xlabel('ë‚ ì§œ', fontsize=12)
    plt.ylabel('ì´í•©', fontsize=12)
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def create_distribution_plots(spark_df, numeric_cols=['amount', 'user_id'], sample_size=10000):
    """ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ ì‹œê°í™” - JSONL ë°ì´í„°ìš©"""
    
    # ìƒ˜í”Œë§
    sample_df = spark_df.sample(fraction=0.1).limit(sample_size).toPandas()
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    existing_numeric_cols = [col for col in numeric_cols if col in sample_df.columns]
    n_cols = len(existing_numeric_cols)
    
    if n_cols == 0:
        print("âŒ ì‹œê°í™”í•  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    fig, axes = plt.subplots((n_cols + 1) // 2, 2, figsize=(15, 4 * ((n_cols + 1) // 2)))
    
    if n_cols == 1:
        axes = [axes]
    elif n_cols <= 2:
        axes = axes.flatten()
    else:
        axes = axes.flatten()
    
    for i, col_name in enumerate(existing_numeric_cols):
        # íˆìŠ¤í† ê·¸ë¨ê³¼ KDE
        sns.histplot(sample_df[col_name], kde=True, ax=axes[i])
        axes[i].set_title(f'{col_name} ë¶„í¬')
        axes[i].grid(True, alpha=0.3)
    
    # ë¹ˆ subplot ì œê±°
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])
    
    plt.tight_layout()
    plt.show()

def create_correlation_heatmap(spark_df, numeric_cols=['amount', 'user_id', 'hour'], sample_size=10000):
    """ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ - JSONL ë°ì´í„°ìš©"""
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    existing_cols = [col for col in numeric_cols if col in spark_df.columns]
    
    if len(existing_cols) < 2:
        print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return
    
    # ìƒ˜í”Œë§
    sample_df = spark_df.select(existing_cols).sample(fraction=0.1).limit(sample_size).toPandas()
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlation_matrix = sample_df.corr()
    
    # íˆíŠ¸ë§µ
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, fmt='.2f')
    plt.title('ë³€ìˆ˜ê°„ ìƒê´€ê´€ê³„', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

class RealTimeMonitor:
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ - JSONL íŒŒí‹°ì…˜ ë°ì´í„°ìš©"""
    
    def __init__(self, spark_session, bucket_name):
        self.spark = spark_session
        self.bucket_name = bucket_name
        self.data_path = f"s3a://{bucket_name}/raw-data/*/*/*/*/data.jsonl"
        self.running = False
    
    def create_dashboard(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        
        # ìœ„ì ¯ ìƒì„±
        self.start_button = widgets.Button(
            description="ëª¨ë‹ˆí„°ë§ ì‹œì‘",
            button_style='success',
            icon='play'
        )
        self.stop_button = widgets.Button(
            description="ì¤‘ì§€",
            button_style='danger',
            icon='stop'
        )
        self.refresh_interval = widgets.IntSlider(
            value=10,
            min=5,
            max=60,
            step=5,
            description='ê°±ì‹  ê°„ê²©(ì´ˆ):',
            style={'description_width': 'initial'}
        )
        self.output = widgets.Output()
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        self.start_button.on_click(self.start_monitoring)
        self.stop_button.on_click(self.stop_monitoring)
        
        # ë ˆì´ì•„ì›ƒ
        controls = widgets.HBox([
            self.start_button, 
            self.stop_button, 
            self.refresh_interval
        ])
        dashboard = widgets.VBox([controls, self.output])
        
        display(dashboard)
    
    def start_monitoring(self, button):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.running = True
        button.disabled = True
        self.stop_button.disabled = False
        self.monitor_loop()
    
    def stop_monitoring(self, button):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.running = False
        self.start_button.disabled = False
        button.disabled = True
    
    def monitor_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.running:
            with self.output:
                clear_output(wait=True)
                self.update_metrics()
            time.sleep(self.refresh_interval.value)
    
    def update_metrics(self):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        try:
            # JSONL ë°ì´í„° ì½ê¸°
            df = self.spark.read.option("multiline", "false").json(self.data_path)
            
            # ìµœê·¼ 1ì‹œê°„ ë°ì´í„°ë§Œ í•„í„°ë§
            current_time = datetime.now()
            recent_data = df.filter(
                col("timestamp").contains(current_time.strftime("%Y-%m-%d"))
            )
            
            total_events = recent_data.count()
            unique_users = recent_data.select("user_id").distinct().count()
            total_amount = recent_data.agg(sum("amount")).collect()[0][0] or 0
            
            print(f"{'='*50}")
            print(f"ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ - {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*50}")
            print(f"ğŸ“Š ì´ ì´ë²¤íŠ¸: {total_events:,}")
            print(f"ğŸ‘¥ í™œì„± ì‚¬ìš©ì: {unique_users:,}")
            print(f"ğŸ’° ì´ ê±°ë˜ì•¡: ${total_amount:,.2f}")
            
            # ìƒìœ„ ì¹´í…Œê³ ë¦¬
            print(f"\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©:")
            if total_events > 0:
                recent_data.groupBy("category") \
                    .agg(count("*").alias("count"), sum("amount").alias("total_amount")) \
                    .orderBy(desc("count")) \
                    .show(5, truncate=False)
                
                # ì´ë²¤íŠ¸ íƒ€ì…ë³„ í˜„í™©
                print(f"\nğŸ” ì´ë²¤íŠ¸ íƒ€ì…ë³„ í˜„í™©:")
                recent_data.groupBy("event_type") \
                    .count() \
                    .orderBy(desc("count")) \
                    .show(5, truncate=False)
            else:
                print("   ë°ì´í„° ì—†ìŒ")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")

def create_business_dashboard(spark_df):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ ìƒì„± - JSONL ë°ì´í„°ìš©"""
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë³€í™˜
    sample_df = spark_df.sample(0.1).limit(5000).toPandas()
    
    # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
    if 'timestamp' in sample_df.columns:
        sample_df['timestamp'] = pd.to_datetime(sample_df['timestamp'])
        sample_df['date'] = sample_df['timestamp'].dt.date
        sample_df['hour'] = sample_df['timestamp'].dt.hour
        sample_df['day_of_week'] = sample_df['timestamp'].dt.day_name()
    
    # ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ì¼ë³„ ë§¤ì¶œ íŠ¸ë Œë“œ
    if 'date' in sample_df.columns and 'amount' in sample_df.columns:
        daily_revenue = sample_df.groupby('date')['amount'].sum().reset_index()
        ax1.plot(daily_revenue['date'], daily_revenue['amount'], marker='o', linewidth=2)
        ax1.set_title('ì¼ë³„ ë§¤ì¶œ íŠ¸ë Œë“œ', fontsize=14, fontweight='bold')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(True, alpha=0.3)
    
    # 2. ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
    if 'category' in sample_df.columns:
        category_dist = sample_df['category'].value_counts()
        ax2.pie(category_dist.values, labels=category_dist.index, autopct='%1.1f%%')
        ax2.set_title('ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬', fontsize=14, fontweight='bold')
    
    # 3. ì‹œê°„ëŒ€ë³„ í™œë™ íˆíŠ¸ë§µ
    if 'hour' in sample_df.columns and 'day_of_week' in sample_df.columns:
        # ìš”ì¼ ìˆœì„œ ì •ì˜
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        
        heatmap_data = sample_df.pivot_table(
            values='amount', 
            index='day_of_week', 
            columns='hour', 
            aggfunc='count',
            fill_value=0
        )
        
        # ìš”ì¼ ìˆœì„œë¡œ ì¬ì •ë ¬
        heatmap_data = heatmap_data.reindex([day for day in day_order if day in heatmap_data.index])
        
        sns.heatmap(heatmap_data, annot=False, cmap='YlOrRd', ax=ax3)
        ax3.set_title('ì‹œê°„ëŒ€ë³„ í™œë™ íˆíŠ¸ë§µ', fontsize=14, fontweight='bold')
    
    # 4. ìƒìœ„ ì‚¬ìš©ì (ê±°ë˜ì•¡ ê¸°ì¤€)
    if 'user_id' in sample_df.columns and 'amount' in sample_df.columns:
        top_users = sample_df.groupby('user_id')['amount'].sum().nlargest(10)
        ax4.barh(range(len(top_users)), top_users.values)
        ax4.set_yticks(range(len(top_users)))
        ax4.set_yticklabels([f'User {uid}' for uid in top_users.index])
        ax4.set_title('ìƒìœ„ 10 ì‚¬ìš©ì (ë§¤ì¶œ ê¸°ì¤€)', fontsize=14, fontweight='bold')
        ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# ì¸í„°ë™í‹°ë¸Œ í•„í„°ë§ ìœ„ì ¯
def create_interactive_filter(spark_df):
    """ì¸í„°ë™í‹°ë¸Œ ë°ì´í„° í•„í„°ë§ ìœ„ì ¯ - JSONL ë°ì´í„°ìš©"""
    
    # ì¹´í…Œê³ ë¦¬ ì˜µì…˜ ìˆ˜ì§‘
    categories = [row[0] for row in spark_df.select("category").distinct().collect()]
    event_types = [row[0] for row in spark_df.select("event_type").distinct().collect()]
    
    # ìœ„ì ¯ ìƒì„±
    category_filter = widgets.SelectMultiple(
        options=categories,
        value=categories[:3] if len(categories) >= 3 else categories,
        description='ì¹´í…Œê³ ë¦¬:',
        style={'description_width': 'initial'}
    )
    
    event_type_filter = widgets.SelectMultiple(
        options=event_types,
        value=event_types[:2] if len(event_types) >= 2 else event_types,
        description='ì´ë²¤íŠ¸ íƒ€ì…:',
        style={'description_width': 'initial'}
    )
    
    amount_threshold = widgets.FloatSlider(
        value=0.0,
        min=0.0,
        max=1000.0,
        step=10.0,
        description='ìµœì†Œ ê¸ˆì•¡:',
        style={'description_width': 'initial'}
    )
    
    output = widgets.Output()
    
    def update_plot(change):
        with output:
            clear_output(wait=True)
            
            # í•„í„°ë§ ì ìš©
            filtered_df = spark_df.filter(
                col("category").isin(list(category_filter.value)) &
                col("event_type").isin(list(event_type_filter.value)) &
                (col("amount") >= amount_threshold.value)
            )
            
            # ê²°ê³¼ í‘œì‹œ
            total_count = filtered_df.count()
            print(f"í•„í„°ë§ ê²°ê³¼: {total_count:,} ë ˆì½”ë“œ")
            
            if total_count > 0:
                print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©:")
                filtered_df.groupBy("category") \
                    .agg(count("*").alias("count"), sum("amount").alias("total_amount")) \
                    .orderBy(desc("count")) \
                    .show(truncate=False)
                
                print(f"\nğŸ” ì´ë²¤íŠ¸ íƒ€ì…ë³„ í˜„í™©:")
                filtered_df.groupBy("event_type") \
                    .agg(count("*").alias("count"), sum("amount").alias("total_amount")) \
                    .orderBy(desc("count")) \
                    .show(truncate=False)
    
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
    category_filter.observe(update_plot, names='value')
    event_type_filter.observe(update_plot, names='value')
    amount_threshold.observe(update_plot, names='value')
    
    # ì´ˆê¸° í”Œë¡¯ ìƒì„±
    update_plot(None)
    
    # ë ˆì´ì•„ì›ƒ
    controls = widgets.VBox([category_filter, event_type_filter, amount_threshold])
    dashboard = widgets.HBox([controls, output])
    
    display(dashboard)

# íŒŒí‹°ì…˜ë³„ ë¶„ì„ í•¨ìˆ˜
def analyze_partitions(spark_df):
    """íŒŒí‹°ì…˜ë³„ ë°ì´í„° ë¶„ì„"""
    
    print("ğŸ“Š íŒŒí‹°ì…˜ë³„ ë°ì´í„° ë¶„ì„")
    print("="*50)
    
    # ì‹œê°„ë³„ ë¶„ì„
    if 'hour' in spark_df.columns:
        print("\nâ° ì‹œê°„ë³„ í˜„í™©:")
        spark_df.groupBy("hour") \
            .agg(count("*").alias("count"), sum("amount").alias("total_amount")) \
            .orderBy("hour") \
            .show(24, truncate=False)
    
    # ì¼ë³„ ë¶„ì„
    if 'day' in spark_df.columns:
        print("\nğŸ“… ì¼ë³„ í˜„í™©:")
        spark_df.groupBy("day") \
            .agg(count("*").alias("count"), sum("amount").alias("total_amount")) \
            .orderBy("day") \
            .show(truncate=False)

if __name__ == "__main__":
    print("âœ… JSONL íŒŒí‹°ì…˜ ë°ì´í„°ìš© ì‹œê°í™” í•¨ìˆ˜ë“¤ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   - visualize_trends(): ì‹œê³„ì—´ íŠ¸ë Œë“œ")
    print("   - create_distribution_plots(): ë¶„í¬ ì‹œê°í™”") 
    print("   - create_correlation_heatmap(): ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
    print("   - RealTimeMonitor(): ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    print("   - create_business_dashboard(): ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ì‹œë³´ë“œ")
    print("   - create_interactive_filter(): ì¸í„°ë™í‹°ë¸Œ í•„í„°")
    print("   - analyze_partitions(): íŒŒí‹°ì…˜ë³„ ë¶„ì„")