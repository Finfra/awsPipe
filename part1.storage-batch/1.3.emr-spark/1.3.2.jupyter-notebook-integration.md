# 1.3.2. Jupyter Notebook 연동

## 개요
EMR 클러스터에서 Jupyter Notebook을 활용한 대화형 데이터 분석 환경 구축

## EMR Studio vs EMR Notebooks
* **EMR Studio**: AWS 관리형 Jupyter 환경 (권장)
* **EMR Notebooks**: 클러스터 직접 설치 방식

## 실행 방법

### 1. EMR Studio 환경 구성
```bash
export s3_bucket_name=$(cat ~/BUCKET_NAME)
read -p "key-pair name = " key_name   # 실제 사용 중인 EC2 키페어 이름으로 교체

cat >setup-jupyter.sh<<EOF
#!/bin/bash
sudo pip install jupyterlab --ignore-installed 
EOF

# 실행 권한 부여
chmod +x setup-jupyter.sh

# S3에 업로드
aws s3 cp setup-jupyter.sh s3://$s3_bucket_name/bootstrap/setup-jupyter.sh

# 업로드 확인
aws s3 ls s3://$s3_bucket_name/bootstrap/

 aws emr create-cluster \
  --name "EMR-Jupyter-Cluster" \
  --release-label emr-6.15.0 \
  --applications Name=Hadoop Name=Spark Name=JupyterHub \
  --service-role EMR_DefaultRole \
  --ec2-attributes InstanceProfile=EMR_EC2_DefaultRole,KeyName=$key_name \
  --instance-type m5.xlarge \
  --instance-count 3 \
  --log-uri s3://$s3_bucket_name/emr-logs/ \
  --bootstrap-actions Path=s3://$s3_bucket_name/bootstrap/setup-jupyter.sh \
  --region ap-northeast-2


CLUSTER_ID=$(aws emr list-clusters --active --query 'Clusters[0].Id' --output text)
echo "Cluster ID: $CLUSTER_ID"

# 클러스터 상태 모니터링
aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.Status.State' --output text

# WAITING 상태까지 대기

# 클러스터가 WAITING 상태가 되면 접속 정보 확인
aws emr describe-cluster --cluster-id $CLUSTER_ID --query 'Cluster.MasterPublicDnsName' --output text
```

### 2. MasterNode의 dns얻기
```bash
aws emr list-instances --cluster-id $CLUSTER_ID --instance-group-types MASTER --query 'Instances[0].PublicDnsName' --output text
```
### 3. ssh로그인 하여 notebook켜기
* 단, 해당 instance의 Security Group확인할 것.
```bash 
export master_url=$(aws emr list-instances --cluster-id $CLUSTER_ID --instance-group-types MASTER --query 'Instances[0].PublicDnsName' --output text)
ssh ec2-user@$master_url
```

### 4. 접속후 NoteBook켜기 
* jupyter lab임. (notebook도 가능)
```
sudo -i 
jupyter lab --no-browser --port=8888 --ip=0.0.0.0 --allow-root
```

### 3. 노트북 환경 초기화 및 s3로딩
```python
%run
from pyspark.sql import SparkSession
from pyspark.sql.functions import input_file_name, regexp_extract, col

spark = SparkSession.builder \
    .appName("Data-Analysis2") \
    .getOrCreate()

bucket_name = "ligkn-0"
raw_data_path = f"s3a://{bucket_name}/raw-data/*/*/*/*/data.jsonl"

# JSONL 파일 읽기
events_df = spark.read \
    .option("multiline", "false") \
    .json(raw_data_path)

# 파티션 정보를 컬럼으로 추가
events_df_with_partitions = events_df \
    .withColumn("file_path", input_file_name()) \
    .withColumn("year", regexp_extract("file_path", r"year=(\d+)", 1).cast("int")) \
    .withColumn("month", regexp_extract("file_path", r"month=(\d+)", 1).cast("int")) \
    .withColumn("day", regexp_extract("file_path", r"day=(\d+)", 1).cast("int")) \
    .withColumn("hour", regexp_extract("file_path", r"hour=(\d+)", 1).cast("int")) \
    .drop("file_path")

# 필터링 (col 함수 사용)
filtered_df = events_df_with_partitions.filter(
    (col("year") == 2024) & 
    (col("month") == 1) & 
    (col("day") == 15) & 
    (col("hour").between(10, 12))
)

# 결과 확인
filtered_df.show()
```

### 4. 시각화 및 대시보드
```python
# 시각화 함수 로드
%run 1.3.2.src/visualization.py
```

### 5. 고급 분석 실행
```python
# 고급 분석 함수 로드
%run 1.3.2.src/advanced-analytics.py
```

## 소스 파일 구성

### 인프라 설정
* **emr-studio.tf**: EMR Studio Terraform 구성
* **setup-jupyter.sh**: 클러스터 직접 Jupyter 설치

### Python 라이브러리
* **notebook-setup.py**: 환경 설정 및 기본 함수
* **visualization.py**: 시각화 및 대시보드 함수
* **advanced-analytics.py**: 고급 분석 및 ML 피처 함수

### 실행 권한 설정
```bash
chmod +x 1.3.2.src/*.sh
```

## 주요 기능

### 대화형 데이터 탐색
* DataFrame 스키마 및 통계 정보 자동 표시
* 샘플링을 통한 대용량 데이터 효율적 탐색
* 결측값 및 데이터 품질 자동 검사

### 실시간 시각화
* Matplotlib/Seaborn 기반 차트 생성
* 인터랙티브 위젯을 통한 필터링
* 실시간 메트릭 모니터링 대시보드

### 고급 분석 기능
* RFM 분석을 통한 고객 세그멘테이션
* 코호트 분석으로 사용자 리텐션 측정
* 이동평균 및 이상치 탐지
* 머신러닝용 피처 엔지니어링

### 성능 최적화
* DataFrame 캐싱 전략
* 브로드캐스트 조인 활용
* 메모리 효율적 스트리밍 처리
* 파티션 최적화

## 접속 방법

### EMR Studio 접속
1. AWS Console → EMR → Studios
2. 생성된 Studio 선택
3. "Open in JupyterLab" 클릭

### 직접 설치 접속
1. **포트 포워딩**: `ssh -L 8888:localhost:8888 hadoop@master-dns`
2. **브라우저 접속**: `http://localhost:8888`
3. **직접 접속**: `http://master-dns:8888` (보안 그룹 8888 포트 오픈 필요)

## 보안 고려사항
* 프로덕션에서는 Jupyter 토큰/패스워드 설정 필수
* VPC 내부 접근만 허용 (보안 그룹 설정)
* IAM 역할 기반 S3 접근 제어
* HTTPS 인증서 설정 권장
